{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#import lightgbm as lgb\n",
    "\n",
    "#pd.options.mode.chained_assignment = None\n",
    "#pd.options.display.max_columns = 999\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns #Visulization\n",
    "\n",
    "from matplotlib import style;\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files with the pandas dataFrame\n",
    "#  pass use the '\\t' delimiter as argument because it is a tab separated file to prevent parser error\n",
    "\n",
    "df_all = pd.read_csv('df_all_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213869, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213861, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_all, test_size=0.05, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203167, 13)\n",
      "(10694, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>condition_label</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163740</td>\n",
       "      <td>Mirtazapine</td>\n",
       "      <td>Depression</td>\n",
       "      <td>\"I&amp;#039;ve tried a few antidepressants over th...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2012-02-28</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>tri antidepress year citalopram fluoxetin amit...</td>\n",
       "      <td>273</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>206473</td>\n",
       "      <td>Mesalamine</td>\n",
       "      <td>Crohn's Disease, Maintenance</td>\n",
       "      <td>\"My son has Crohn&amp;#039;s disease and has done ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2009-05-17</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>son crohn diseas done well asacol no complaint...</td>\n",
       "      <td>253</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>159672</td>\n",
       "      <td>Bactrim</td>\n",
       "      <td>Urinary Tract Infection</td>\n",
       "      <td>\"Quick reduction of symptoms\"</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017-09-29</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>quick reduct symptom</td>\n",
       "      <td>847</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>39293</td>\n",
       "      <td>Contrave</td>\n",
       "      <td>Weight Loss</td>\n",
       "      <td>\"Contrave combines drugs that were used for al...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017-03-05</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>contrav combin drug use alcohol smoke opioid c...</td>\n",
       "      <td>869</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>97768</td>\n",
       "      <td>Cyclafem 1 / 35</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I have been on this birth control for one cyc...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>birth control one cycl read review type simila...</td>\n",
       "      <td>175</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>208087</td>\n",
       "      <td>Zyclara</td>\n",
       "      <td>Keratosis</td>\n",
       "      <td>\"4 days in on first 2 weeks.  Using on arms an...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2014-07-03</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>day first week use arm face put vaselin lip ey...</td>\n",
       "      <td>473</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>215892</td>\n",
       "      <td>Copper</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I&amp;#039;ve had the copper coil for about 3 mon...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016-06-06</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>copper coil month realli excit thought not tak...</td>\n",
       "      <td>175</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>169852</td>\n",
       "      <td>Amitriptyline</td>\n",
       "      <td>Migraine Prevention</td>\n",
       "      <td>\"This has been great for me. I&amp;#039;ve been on...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2009-04-21</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>great week last week headach went away tylenol...</td>\n",
       "      <td>522</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>23295</td>\n",
       "      <td>Methadone</td>\n",
       "      <td>Opiate Withdrawal</td>\n",
       "      <td>\"Ive been on Methadone for over ten years and ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>2016</td>\n",
       "      <td>ive methadon ten year current tri get drug ive...</td>\n",
       "      <td>594</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>71428</td>\n",
       "      <td>Levora</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I was on this pill for almost two years. It d...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011-04-16</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>pill almost two year work far not get pregnant...</td>\n",
       "      <td>175</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Id         drugName                     condition  \\\n",
       "0           0  163740      Mirtazapine                    Depression   \n",
       "1           1  206473       Mesalamine  Crohn's Disease, Maintenance   \n",
       "2           2  159672          Bactrim       Urinary Tract Infection   \n",
       "3           3   39293         Contrave                   Weight Loss   \n",
       "4           4   97768  Cyclafem 1 / 35                 Birth Control   \n",
       "5           5  208087          Zyclara                     Keratosis   \n",
       "6           6  215892           Copper                 Birth Control   \n",
       "7           7  169852    Amitriptyline           Migraine Prevention   \n",
       "8           8   23295        Methadone             Opiate Withdrawal   \n",
       "9           9   71428           Levora                 Birth Control   \n",
       "\n",
       "                                              review  rating        date  \\\n",
       "0  \"I&#039;ve tried a few antidepressants over th...    10.0  2012-02-28   \n",
       "1  \"My son has Crohn&#039;s disease and has done ...     8.0  2009-05-17   \n",
       "2                      \"Quick reduction of symptoms\"     9.0  2017-09-29   \n",
       "3  \"Contrave combines drugs that were used for al...     9.0  2017-03-05   \n",
       "4  \"I have been on this birth control for one cyc...     9.0  2015-10-22   \n",
       "5  \"4 days in on first 2 weeks.  Using on arms an...     4.0  2014-07-03   \n",
       "6  \"I&#039;ve had the copper coil for about 3 mon...     6.0  2016-06-06   \n",
       "7  \"This has been great for me. I&#039;ve been on...     9.0  2009-04-21   \n",
       "8  \"Ive been on Methadone for over ten years and ...     7.0  2016-10-18   \n",
       "9  \"I was on this pill for almost two years. It d...     2.0  2011-04-16   \n",
       "\n",
       "   usefulCount  month  year  \\\n",
       "0           22      2  2012   \n",
       "1           17      5  2009   \n",
       "2            3      9  2017   \n",
       "3           35      3  2017   \n",
       "4            4     10  2015   \n",
       "5           13      7  2014   \n",
       "6            1      6  2016   \n",
       "7           32      4  2009   \n",
       "8           21     10  2016   \n",
       "9            3      4  2011   \n",
       "\n",
       "                                        review_clean  condition_label  day  \n",
       "0  tri antidepress year citalopram fluoxetin amit...              273   28  \n",
       "1  son crohn diseas done well asacol no complaint...              253   17  \n",
       "2                               quick reduct symptom              847   29  \n",
       "3  contrav combin drug use alcohol smoke opioid c...              869    5  \n",
       "4  birth control one cycl read review type simila...              175   22  \n",
       "5  day first week use arm face put vaselin lip ey...              473    3  \n",
       "6  copper coil month realli excit thought not tak...              175    6  \n",
       "7  great week last week headach went away tylenol...              522   21  \n",
       "8  ive methadon ten year current tri get drug ive...              594   18  \n",
       "9  pill almost two year work far not get pregnant...              175   16  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\CK-\n",
      "[nltk_data]     Lab\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['vaderReviewScore'] = df_all['review_clean'].apply(lambda x: sid.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>condition_label</th>\n",
       "      <th>day</th>\n",
       "      <th>vaderReviewScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>163740</td>\n",
       "      <td>Mirtazapine</td>\n",
       "      <td>Depression</td>\n",
       "      <td>\"I&amp;#039;ve tried a few antidepressants over th...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2012-02-28</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>tri antidepress year citalopram fluoxetin amit...</td>\n",
       "      <td>273</td>\n",
       "      <td>28</td>\n",
       "      <td>0.8470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>206473</td>\n",
       "      <td>Mesalamine</td>\n",
       "      <td>Crohn's Disease, Maintenance</td>\n",
       "      <td>\"My son has Crohn&amp;#039;s disease and has done ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2009-05-17</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>son crohn diseas done well asacol no complaint...</td>\n",
       "      <td>253</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>159672</td>\n",
       "      <td>Bactrim</td>\n",
       "      <td>Urinary Tract Infection</td>\n",
       "      <td>\"Quick reduction of symptoms\"</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017-09-29</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>quick reduct symptom</td>\n",
       "      <td>847</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>39293</td>\n",
       "      <td>Contrave</td>\n",
       "      <td>Weight Loss</td>\n",
       "      <td>\"Contrave combines drugs that were used for al...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017-03-05</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>contrav combin drug use alcohol smoke opioid c...</td>\n",
       "      <td>869</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>97768</td>\n",
       "      <td>Cyclafem 1 / 35</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I have been on this birth control for one cyc...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>birth control one cycl read review type simila...</td>\n",
       "      <td>175</td>\n",
       "      <td>22</td>\n",
       "      <td>0.8834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Id         drugName                     condition  \\\n",
       "0           0  163740      Mirtazapine                    Depression   \n",
       "1           1  206473       Mesalamine  Crohn's Disease, Maintenance   \n",
       "2           2  159672          Bactrim       Urinary Tract Infection   \n",
       "3           3   39293         Contrave                   Weight Loss   \n",
       "4           4   97768  Cyclafem 1 / 35                 Birth Control   \n",
       "\n",
       "                                              review  rating        date  \\\n",
       "0  \"I&#039;ve tried a few antidepressants over th...    10.0  2012-02-28   \n",
       "1  \"My son has Crohn&#039;s disease and has done ...     8.0  2009-05-17   \n",
       "2                      \"Quick reduction of symptoms\"     9.0  2017-09-29   \n",
       "3  \"Contrave combines drugs that were used for al...     9.0  2017-03-05   \n",
       "4  \"I have been on this birth control for one cyc...     9.0  2015-10-22   \n",
       "\n",
       "   usefulCount  month  year  \\\n",
       "0           22      2  2012   \n",
       "1           17      5  2009   \n",
       "2            3      9  2017   \n",
       "3           35      3  2017   \n",
       "4            4     10  2015   \n",
       "\n",
       "                                        review_clean  condition_label  day  \\\n",
       "0  tri antidepress year citalopram fluoxetin amit...              273   28   \n",
       "1  son crohn diseas done well asacol no complaint...              253   17   \n",
       "2                               quick reduct symptom              847   29   \n",
       "3  contrav combin drug use alcohol smoke opioid c...              869    5   \n",
       "4  birth control one cycl read review type simila...              175   22   \n",
       "\n",
       "   vaderReviewScore  \n",
       "0            0.8470  \n",
       "1           -0.5423  \n",
       "2            0.0000  \n",
       "3            0.5106  \n",
       "4            0.8834  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_all[\"vaderReviewScore\"].plot(kind=\"hist\", color='green', bins=40, figsize = (10,6), fontsize = 20)\n",
    "plt.xlabel('Scores', fontsize = 20)\n",
    "plt.ylabel('Count', fontsize = 20)\n",
    "plt.savefig(\"sentiment_analysis\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vaderScores = df_all.groupby('rating')['vaderReviewScore'].mean()\n",
    "vaderScores.plot(kind=\"bar\", figsize = (10,6), fontsize = 20, color=\"green\")\n",
    "plt.xlabel(\"Rating\", fontsize = 20)\n",
    "plt.ylabel(\"Avg. Sentiment Score\", fontsize = 20)\n",
    "plt.savefig(\"sentiment_rating\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize with Count of N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgramFeatures(minNgram, maxNgram, df_train, df_test, num_features = 2000):\n",
    "    vectorizer = CountVectorizer(analyzer = 'word', \n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None, \n",
    "                             stop_words = None, \n",
    "                             min_df = 2,\n",
    "                             ngram_range = (minNgram, maxNgram),\n",
    "                             max_features = num_features\n",
    "                            )\n",
    "    print(vectorizer)\n",
    "    \n",
    "    train_data_features = vectorizer.fit_transform(df_train['review_clean'])\n",
    "    test_data_features = vectorizer.transform(df_test['review_clean'])\n",
    "    \n",
    "    return train_data_features, test_data_features, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFIDFFeatures(minNgram, maxNgram, df_train, df_test, num_features = 2000):\n",
    "    vectorizer = TfidfVectorizer(analyzer = 'word', \n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None, \n",
    "                             stop_words = None, \n",
    "                             min_df = 2,\n",
    "                             ngram_range = (minNgram, maxNgram),\n",
    "                             max_features = num_features\n",
    "                            )\n",
    "    print(vectorizer)\n",
    "    \n",
    "    train_data_features = vectorizer.fit_transform(df_train['review_clean'])\n",
    "    test_data_features = vectorizer.transform(df_test['review_clean'])\n",
    "    \n",
    "    return train_data_features, test_data_features, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regresion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinearRegressionResults(train_x, train_y, test_x, test_y):\n",
    "    lin_reg = LinearRegression()\n",
    "    \n",
    "    print(lin_reg)\n",
    "    \n",
    "    lin_reg.fit(train_x, train_y)\n",
    "    \n",
    "    train_pred = lin_reg.predict(train_x)\n",
    "    test_pred = lin_reg.predict(test_x)\n",
    "    \n",
    "    test_mse = metrics.mean_squared_error(test_y, test_pred)\n",
    "    test_rmse = np.sqrt(metrics.mean_absolute_error(test_y, test_pred))\n",
    "    test_r2 = metrics.r2_score(test_y, test_pred)\n",
    "    \n",
    "    train_mse = metrics.mean_squared_error(train_y, train_pred)\n",
    "    train_rmse = np.sqrt(metrics.mean_absolute_error(train_y, train_pred))\n",
    "    train_r2 = metrics.r2_score(train_y, train_pred)\n",
    "    \n",
    "    print(\"TRAIN: MSE: %f, RMSE: %f, R^2: %f\" % (train_mse, train_rmse, train_r2))\n",
    "    print(\"TEST: MSE: %f, RMSE: %f, R^2: %f\" % (test_mse, test_rmse, test_r2))\n",
    "    \n",
    "    return lin_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRidgeRegressionResults(C, train_x, train_y, test_x, test_y):\n",
    "    lin_reg = Ridge(alpha=C)\n",
    "    \n",
    "    print(lin_reg)\n",
    "    \n",
    "    lin_reg.fit(train_x, train_y)\n",
    "    \n",
    "    train_pred = lin_reg.predict(train_x)\n",
    "    test_pred = lin_reg.predict(test_x)\n",
    "    \n",
    "    test_mse = metrics.mean_squared_error(test_y, test_pred)\n",
    "    test_rmse = np.sqrt(metrics.mean_absolute_error(test_y, test_pred))\n",
    "    test_r2 = metrics.r2_score(test_y, test_pred)\n",
    "    \n",
    "    train_mse = metrics.mean_squared_error(train_y, train_pred)\n",
    "    train_rmse = np.sqrt(metrics.mean_absolute_error(train_y, train_pred))\n",
    "    train_r2 = metrics.r2_score(train_y, train_pred)\n",
    "    \n",
    "    print(\"Ridge(alpha=%f)\" % (C))\n",
    "    print(\"TRAIN: MSE: %f, RMSE: %f, R^2: %f\" % (train_mse, train_rmse, train_r2))\n",
    "    print(\"TEST: MSE: %f, RMSE: %f, R^2: %f\" % (test_mse, test_rmse, test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKernelRidgeRegressionResults(train_x, train_y, test_x, test_y):\n",
    "    kr = GridSearchCV(KernelRidge(kernel='rbf', gamma=0.1), cv=5,\n",
    "                  param_grid={\"alpha\": [1e0, 0.1, 1e-2, 1e-3],\n",
    "                              \"gamma\": np.logspace(-2, 2, 5)})\n",
    "    \n",
    "    kr.fit(train_x, train_y)\n",
    "    \n",
    "    train_pred = kr.predict(train_x)\n",
    "    test_pred = kr.predict(test_x)\n",
    "    \n",
    "    test_mse = metrics.mean_squared_error(test_y, test_pred)\n",
    "    test_rmse = np.sqrt(metrics.mean_absolute_error(test_y, test_pred))\n",
    "    test_r2 = metrics.r2_score(test_y, test_pred)\n",
    "    \n",
    "    train_mse = metrics.mean_squared_error(train_y, train_pred)\n",
    "    train_rmse = np.sqrt(metrics.mean_absolute_error(train_y, train_pred))\n",
    "    train_r2 = metrics.r2_score(train_y, train_pred)\n",
    "    \n",
    "    print(\"TRAIN: MSE: %f, RMSE: %f, R^2: %f\" % (train_mse, train_rmse, train_r2))\n",
    "    print(\"TEST: MSE: %f, RMSE: %f, R^2: %f\" % (test_mse, test_rmse, test_r2))\n",
    "    \n",
    "    return kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomForestRegressionResults(train_x, train_y, test_x, test_y):\n",
    "    rfr = RandomForestRegressor(n_estimators=10, verbose = 10, n_jobs = 4)\n",
    "\n",
    "    rfr.fit(train_x, train_y)\n",
    "    \n",
    "    train_pred = rfr.predict(train_x)\n",
    "    test_pred = rfr.predict(test_x)\n",
    "    \n",
    "    test_mse = metrics.mean_squared_error(test_y, test_pred)\n",
    "    test_rmse = np.sqrt(metrics.mean_absolute_error(test_y, test_pred))\n",
    "    test_r2 = metrics.r2_score(test_y, test_pred)\n",
    "    \n",
    "    train_mse = metrics.mean_squared_error(train_y, train_pred)\n",
    "    train_rmse = np.sqrt(metrics.mean_absolute_error(train_y, train_pred))\n",
    "    train_r2 = metrics.r2_score(train_y, train_pred)\n",
    "    \n",
    "    print(\"TRAIN: MSE: %f, RMSE: %f, R^2: %f\" % (train_mse, train_rmse, train_r2))\n",
    "    print(\"TEST: MSE: %f, RMSE: %f, R^2: %f\" % (test_mse, test_rmse, test_r2))\n",
    "    \n",
    "    return rfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXGBoostRegressionResults(train_x, train_y, test_x, test_y, n_est=50):\n",
    "    \n",
    "    gbr = XGBRegressor(n_estimators=n_est)\n",
    "\n",
    "    print(gbr)\n",
    "    \n",
    "    gbr.fit(train_x, train_y)\n",
    "    \n",
    "    train_pred = gbr.predict(train_x)\n",
    "    test_pred = gbr.predict(test_x)\n",
    "    \n",
    "    test_mse = metrics.mean_squared_error(test_y, test_pred)\n",
    "    test_rmse = np.sqrt(metrics.mean_absolute_error(test_y, test_pred))\n",
    "    test_r2 = metrics.r2_score(test_y, test_pred)\n",
    "    \n",
    "    train_mse = metrics.mean_squared_error(train_y, train_pred)\n",
    "    train_rmse = np.sqrt(metrics.mean_absolute_error(train_y, train_pred))\n",
    "    train_r2 = metrics.r2_score(train_y, train_pred)\n",
    "    \n",
    "    print(\"TRAIN: MSE: %f, RMSE: %f, R^2: %f\" % (train_mse, train_rmse, train_r2))\n",
    "    print(\"TEST: MSE: %f, RMSE: %f, R^2: %f\" % (test_mse, test_rmse, test_r2))\n",
    "    \n",
    "    return gbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203167, 22)\n",
      "(10694, 22)\n"
     ]
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(categories='auto')\n",
    "enc.fit(df_train[[\"month\",\"year\"]].to_numpy())\n",
    "train_onehotlabels = enc.transform(df_train[[\"month\",\"year\"]].to_numpy()).toarray()\n",
    "print(train_onehotlabels.shape)\n",
    "test_onehotlabels = enc.transform(df_test[[\"month\",\"year\"]].to_numpy()).toarray()\n",
    "print(test_onehotlabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding month, year, condition_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203167, 22)\n",
      "(10694, 22)\n",
      "(203167, 916)\n",
      "(10694, 916)\n",
      "(203167, 938)\n",
      "(10694, 938)\n"
     ]
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(categories='auto')\n",
    "enc.fit(df_train[[\"month\",\"year\"]].to_numpy())\n",
    "train_onehotlabels_date = enc.transform(df_train[[\"month\",\"year\"]].to_numpy()).toarray()\n",
    "print(train_onehotlabels_date.shape)\n",
    "test_onehotlabels_date = enc.transform(df_test[[\"month\",\"year\"]].to_numpy()).toarray()\n",
    "print(test_onehotlabels_date.shape)\n",
    "\n",
    "enc = preprocessing.OneHotEncoder(categories=[list(range(0,916))])\n",
    "enc.fit(df_train[[\"condition_label\"]].to_numpy())\n",
    "train_onehotlabels_condition = enc.transform(df_train[[\"condition_label\"]].to_numpy()).toarray()\n",
    "print(train_onehotlabels_condition.shape)\n",
    "test_onehotlabels_condition = enc.transform(df_test[[\"condition_label\"]].to_numpy()).toarray()\n",
    "print(test_onehotlabels_condition.shape)\n",
    "\n",
    "train_onehotlabels = np.concatenate((train_onehotlabels_date, train_onehotlabels_condition), axis=1)\n",
    "test_onehotlabels = np.concatenate((test_onehotlabels_date, test_onehotlabels_condition), axis=1)\n",
    "print(train_onehotlabels.shape)\n",
    "print(test_onehotlabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding month, year, day, and condition_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203167, 53)\n",
      "(10694, 53)\n",
      "(203167, 916)\n",
      "(10694, 916)\n",
      "(203167, 969)\n",
      "(10694, 969)\n"
     ]
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(categories='auto')\n",
    "enc.fit(df_all[[\"month\",\"year\",\"day\"]].to_numpy())\n",
    "train_onehotlabels_date = enc.transform(df_train[[\"month\",\"year\",\"day\"]].to_numpy()).toarray()\n",
    "print(train_onehotlabels_date.shape)\n",
    "test_onehotlabels_date = enc.transform(df_test[[\"month\",\"year\",\"day\"]].to_numpy()).toarray()\n",
    "print(test_onehotlabels_date.shape)\n",
    "\n",
    "enc = preprocessing.OneHotEncoder(categories=[list(range(0,916))])\n",
    "enc.fit(df_train[[\"condition_label\"]].to_numpy())\n",
    "train_onehotlabels_condition = enc.transform(df_train[[\"condition_label\"]].to_numpy()).toarray()\n",
    "print(train_onehotlabels_condition.shape)\n",
    "test_onehotlabels_condition = enc.transform(df_test[[\"condition_label\"]].to_numpy()).toarray()\n",
    "print(test_onehotlabels_condition.shape)\n",
    "\n",
    "train_onehotlabels = np.concatenate((train_onehotlabels_date, train_onehotlabels_condition), axis=1)\n",
    "test_onehotlabels = np.concatenate((test_onehotlabels_date, test_onehotlabels_condition), axis=1)\n",
    "print(train_onehotlabels.shape)\n",
    "print(test_onehotlabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=5000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 5000)\n",
      "(10694, 5000)\n",
      "(203167, 5969)\n",
      "(10694, 5969)\n",
      "(203167, 5970)\n",
      "(10694, 5970)\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "             max_depth=3, min_child_weight=1, missing=None, n_estimators=3000,\n",
      "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "             silent=None, subsample=1, verbosity=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:31:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-7732e74d036a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mxgbModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetXGBoostRegressionResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-0ff7c437cda1>\u001b[0m in \u001b[0;36mgetXGBoostRegressionResults\u001b[0;34m(train_x, train_y, test_x, test_y, n_est)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mgbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### XGBOOST plot_importance\n",
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "numFeatures = 5000\n",
    "max_ngram = 2\n",
    "min_ngram = 1\n",
    "n_est = 3000\n",
    "\n",
    "print(\"\\nRunnpipelineing ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "print(train_data_features.shape)\n",
    "print(test_data_features.shape)\n",
    "\n",
    "train_features = hstack((train_data_features,train_onehotlabels))\n",
    "test_features = hstack((test_data_features,test_onehotlabels))\n",
    "\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "xgbModel = getXGBoostRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"], n_est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(xgbModel, max_num_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=35000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35969)\n",
      "(10694, 35969)\n",
      "(203167, 35970)\n",
      "(10694, 35970)\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "TRAIN: MSE: 3.527218, RMSE: 1.217231, R^2: 0.671063\n",
      "TEST: MSE: 5.177190, RMSE: 1.343337, R^2: 0.524129\n",
      "[(4.321343364633374, 'magnesia'), (4.29843751729137, 'pump inhibitor'), (4.067326971397034, 'prostat hyperplasia'), (3.7371021141041068, 'dysphor disord'), (3.554775388160428, 'natur throid'), (3.4093453253859147, 'tri nessa'), (2.886755774105202, 'bleed complet'), (2.676074900981687, 'ice cube'), (2.4535659436215846, 'estrin'), (2.4209459225617063, 'folic'), (2.2968470976275706, 'john wort'), (2.283192482760353, 'lens'), (2.2609399659621126, 'basket case'), (2.2092137565719456, 'energi sex'), (2.1225529538594428, 'like clock'), (2.097304422400858, 'esteem'), (2.064054422205211, 'peopl thought'), (2.0575817243235073, 'tempor'), (2.024722243572663, 'deal breaker'), (2.022677366820685, 'current dose')]\n",
      "[(-2.3848240609109452, 'hope miracl'), (-2.393175542071866, 'tardiv dyskinesia'), (-2.397678380108601, 'clock work'), (-2.4572022891839524, 'scam'), (-2.4715661826212862, 'not curb'), (-2.4873901567804437, 'put depress'), (-2.4986754436692693, 'zero effect'), (-2.5574565229990944, 'littlest'), (-2.562511914430241, 'took direct'), (-2.5982248744809198, 'breaker'), (-2.611963252414801, 'no better'), (-2.697721889834115, 'right also'), (-2.926935752348598, 'no benefit'), (-2.9670004737799616, 'premenstru dysphor'), (-2.9845114145849796, 'cube'), (-3.1740701830093134, 'nessa'), (-3.4013494810309544, 'throid'), (-4.443958224259067, 'milk magnesia'), (-4.635971964648935, 'benign prostat'), (-5.1619674368451065, 'proton pump')]\n"
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "for numFeatures in [35000]:\n",
    "    for max_ngram in [2]: \n",
    "        min_ngram = 1\n",
    "\n",
    "        print(\"\\nRunning ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "        train_data_features, test_data_features, vc = getNgramFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "        print(train_data_features.shape)\n",
    "        print(test_data_features.shape)\n",
    "\n",
    "        train_features = hstack((train_data_features,train_onehotlabels))\n",
    "        test_features = hstack((test_data_features,test_onehotlabels))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "        test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        model = getLinearRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "        CoefNames.sort(reverse=True)\n",
    "        print(CoefNames[:20])\n",
    "        print(CoefNames[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4.321343364633374, 'magnesia'), (4.29843751729137, 'pump inhibitor'), (4.067326971397034, 'prostat hyperplasia'), (3.7371021141041068, 'dysphor disord'), (3.554775388160428, 'natur throid'), (3.4093453253859147, 'tri nessa'), (2.886755774105202, 'bleed complet'), (2.676074900981687, 'ice cube'), (2.4535659436215846, 'estrin'), (2.4209459225617063, 'folic'), (2.2968470976275706, 'john wort'), (2.283192482760353, 'lens'), (2.2609399659621126, 'basket case'), (2.2092137565719456, 'energi sex'), (2.1225529538594428, 'like clock'), (2.097304422400858, 'esteem'), (2.064054422205211, 'peopl thought'), (2.0575817243235073, 'tempor'), (2.024722243572663, 'deal breaker'), (2.022677366820685, 'current dose'), (1.9844953971352732, 'last ditch'), (1.9808545884367466, 'size amount'), (1.9328754986205916, 'hive free'), (1.8980472997188569, 'game changer'), (1.8901044261174809, 'life changer'), (1.8759572990688327, 'never reaction'), (1.8354110784397963, 'alway look'), (1.8127672116791766, 'lidoderm patch'), (1.8073786050985334, 'sclerosi'), (1.8059654081379886, 'find pharmaci'), (1.7976932283034324, 'back live'), (1.7943530535821262, 'pound back'), (1.7889938593015202, 'clear problem'), (1.7698682735050288, 'face began'), (1.7689807502812889, 'maxalt mlt'), (1.7672710661719266, 'fit pal'), (1.763372647660745, 'bi polar'), (1.7565650331583478, 'dead track'), (1.7426325620656296, 'stuff done'), (1.7407516713097742, 'ivi'), (1.7318079141204188, 'back fine'), (1.7251910415199478, 'day bp'), (1.7112870077129878, 'chang qualiti'), (1.7076960668488246, 'littlest thing'), (1.704816312074124, 'understand peopl'), (1.6976346243072902, 'sever infect'), (1.6876894754289444, 'take benzo'), (1.6826549933789476, 'would bad'), (1.6790267335779403, 'woke time'), (1.676916712416865, 'negat say')]\n",
      "[(-1.9513620828632239, 'not reliev'), (-1.9572268384876141, 'decis could'), (-1.9581627659570762, 'hate relationship'), (-1.9584060372349261, 'no good'), (-1.9690824433265228, 'lo estrin'), (-1.9713868126954677, 'say wait'), (-1.9723539101825684, 'one pound'), (-1.9881782404201989, 'no improv'), (-1.9885063220723733, 'diovan hct'), (-1.9933510957621692, 'not signific'), (-2.0046006345730705, 'went depress'), (-2.0155629547679963, 'toilet paper'), (-2.022964283366489, 'worst drug'), (-2.031219683436728, 'mlt'), (-2.043610086964298, 'worst medic'), (-2.060787820456974, 'relief go'), (-2.084015501074281, 'suffer great'), (-2.1262140616540686, 'week mani'), (-2.1286829514770105, 'seem anyth'), (-2.1612480091512336, 'effect kind'), (-2.181951010214274, 'yes help'), (-2.1967828350484355, 'pleas care'), (-2.2042515966550034, 'ultra sound'), (-2.2066114913231796, 'no magic'), (-2.248607207190051, 'self esteem'), (-2.2834637069107635, 'sound great'), (-2.2880771194232885, 'aggrenox'), (-2.308458772635683, 'projectil vomit'), (-2.3430451692090846, 'not impress'), (-2.36053726607371, 'may good'), (-2.3848240609109452, 'hope miracl'), (-2.393175542071866, 'tardiv dyskinesia'), (-2.397678380108601, 'clock work'), (-2.4572022891839524, 'scam'), (-2.4715661826212862, 'not curb'), (-2.4873901567804437, 'put depress'), (-2.4986754436692693, 'zero effect'), (-2.5574565229990944, 'littlest'), (-2.562511914430241, 'took direct'), (-2.5982248744809198, 'breaker'), (-2.611963252414801, 'no better'), (-2.697721889834115, 'right also'), (-2.926935752348598, 'no benefit'), (-2.9670004737799616, 'premenstru dysphor'), (-2.9845114145849796, 'cube'), (-3.1740701830093134, 'nessa'), (-3.4013494810309544, 'throid'), (-4.443958224259067, 'milk magnesia'), (-4.635971964648935, 'benign prostat'), (-5.1619674368451065, 'proton pump')]\n"
     ]
    }
   ],
   "source": [
    "        CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "        CoefNames.sort(reverse=True)\n",
    "        print(CoefNames[:50])\n",
    "        print(CoefNames[-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=35000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35969)\n",
      "(10694, 35969)\n",
      "(203167, 35970)\n",
      "(10694, 35970)\n",
      "Ridge(alpha=0.010000)\n",
      "TRAIN: MSE: 5.780887, RMSE: 1.395481, R^2: 0.460894\n",
      "TEST: MSE: 5.894450, RMSE: 1.402386, R^2: 0.458201\n",
      "Ridge(alpha=0.050000)\n",
      "TRAIN: MSE: 5.780875, RMSE: 1.395481, R^2: 0.460895\n",
      "TEST: MSE: 5.894444, RMSE: 1.402386, R^2: 0.458202\n",
      "Ridge(alpha=0.100000)\n",
      "TRAIN: MSE: 5.780874, RMSE: 1.395480, R^2: 0.460895\n",
      "TEST: MSE: 5.894439, RMSE: 1.402386, R^2: 0.458202\n",
      "Ridge(alpha=0.500000)\n",
      "TRAIN: MSE: 5.780931, RMSE: 1.395486, R^2: 0.460890\n",
      "TEST: MSE: 5.894484, RMSE: 1.402392, R^2: 0.458198\n",
      "Ridge(alpha=1.000000)\n",
      "TRAIN: MSE: 5.780958, RMSE: 1.395487, R^2: 0.460887\n",
      "TEST: MSE: 5.894502, RMSE: 1.402392, R^2: 0.458196\n",
      "Ridge(alpha=10.000000)\n",
      "TRAIN: MSE: 5.782867, RMSE: 1.395618, R^2: 0.460709\n",
      "TEST: MSE: 5.896306, RMSE: 1.402516, R^2: 0.458030\n",
      "Ridge(alpha=100.000000)\n",
      "TRAIN: MSE: 5.799798, RMSE: 1.396775, R^2: 0.459130\n",
      "TEST: MSE: 5.911933, RMSE: 1.403604, R^2: 0.456594\n"
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "for numFeatures in [35000]:\n",
    "    for max_ngram in [2]: \n",
    "        min_ngram = 1\n",
    "\n",
    "        print(\"\\nRunning ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "        train_data_features, test_data_features, vc = getNgramFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "        print(train_data_features.shape)\n",
    "        print(test_data_features.shape)\n",
    "\n",
    "        train_features = hstack((train_data_features,train_onehotlabels))\n",
    "        test_features = hstack((test_data_features,test_onehotlabels))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "        test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        #model = getLinearRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        for c in [0.01, 0.05, 0.1, 0.5, 1, 10, 100]:\n",
    "            getRidgeRegressionResults(c, train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "#         CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "#         CoefNames.sort(reverse=True)\n",
    "#         print(CoefNames[:10])\n",
    "#         print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=35000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35969)\n",
      "(10694, 35969)\n",
      "(203167, 35970)\n",
      "(10694, 35970)\n",
      "TRAIN: MSE: 3.104866, RMSE: 1.176297, R^2: 0.710450\n",
      "TEST: MSE: 4.650286, RMSE: 1.302979, R^2: 0.572561\n",
      "Ridge(alpha=0, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
      "      random_state=None, solver='auto', tol=0.001)\n",
      "Ridge(alpha=0.000000)\n",
      "TRAIN: MSE: 8.842596, RMSE: 1.582652, R^2: 0.175369\n",
      "TEST: MSE: 9.046916, RMSE: 1.592696, R^2: 0.168436\n",
      "Ridge(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge(alpha=0.001000)\n",
      "TRAIN: MSE: 8.842598, RMSE: 1.582651, R^2: 0.175369\n",
      "TEST: MSE: 9.046921, RMSE: 1.592695, R^2: 0.168436\n",
      "Ridge(alpha=0.005, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge(alpha=0.005000)\n",
      "TRAIN: MSE: 8.842605, RMSE: 1.582653, R^2: 0.175368\n",
      "TEST: MSE: 9.046933, RMSE: 1.592697, R^2: 0.168435\n",
      "Ridge(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge(alpha=0.010000)\n",
      "TRAIN: MSE: 8.842607, RMSE: 1.582651, R^2: 0.175368\n",
      "TEST: MSE: 9.046924, RMSE: 1.592694, R^2: 0.168436\n",
      "Ridge(alpha=0.05, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge(alpha=0.050000)\n",
      "TRAIN: MSE: 8.842617, RMSE: 1.582654, R^2: 0.175367\n",
      "TEST: MSE: 9.046939, RMSE: 1.592697, R^2: 0.168434\n",
      "Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge(alpha=0.100000)\n",
      "TRAIN: MSE: 8.842617, RMSE: 1.582652, R^2: 0.175367\n",
      "TEST: MSE: 9.046932, RMSE: 1.592696, R^2: 0.168435\n",
      "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge(alpha=0.500000)\n",
      "TRAIN: MSE: 8.842657, RMSE: 1.582654, R^2: 0.175363\n",
      "TEST: MSE: 9.046981, RMSE: 1.592697, R^2: 0.168430\n",
      "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
      "      random_state=None, solver='auto', tol=0.001)\n",
      "Ridge(alpha=1.000000)\n",
      "TRAIN: MSE: 8.842724, RMSE: 1.582660, R^2: 0.175357\n",
      "TEST: MSE: 9.047038, RMSE: 1.592703, R^2: 0.168425\n",
      "Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
      "      random_state=None, solver='auto', tol=0.001)\n",
      "Ridge(alpha=10.000000)\n",
      "TRAIN: MSE: 8.844768, RMSE: 1.582774, R^2: 0.175166\n",
      "TEST: MSE: 9.049109, RMSE: 1.592815, R^2: 0.168235\n",
      "Ridge(alpha=100, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge(alpha=100.000000)\n",
      "TRAIN: MSE: 8.862022, RMSE: 1.583758, R^2: 0.173557\n",
      "TEST: MSE: 9.066561, RMSE: 1.593786, R^2: 0.166631\n",
      "Ridge(alpha=1000, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "Ridge(alpha=1000.000000)\n",
      "TRAIN: MSE: 9.003659, RMSE: 1.591708, R^2: 0.160349\n",
      "TEST: MSE: 9.209655, RMSE: 1.601655, R^2: 0.153478\n"
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "for numFeatures in [35000]:\n",
    "    for max_ngram in [2]: \n",
    "        min_ngram = 1\n",
    "\n",
    "        print(\"\\nRunning ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "        train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "        print(train_data_features.shape)\n",
    "        print(test_data_features.shape)\n",
    "\n",
    "        train_features = hstack((train_data_features,train_onehotlabels))\n",
    "        test_features = hstack((test_data_features,test_onehotlabels))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "        test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        getLinearRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        for c in [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 10, 100, 1000]:\n",
    "            getRidgeRegressionResults(c, train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "#         CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "#         CoefNames.sort(reverse=True)\n",
    "#         print(CoefNames[:10])\n",
    "#         print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ngram(1, 1)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=2000, min_df=2,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(164672, 2000)\n",
      "(49189, 2000)\n",
      "(164672, 2022)\n",
      "(49189, 2022)\n",
      "TRAIN: MSE: 6.247339, RMSE: 1.423504, R^2: 0.417359\n",
      "TEST: MSE: 6.377374, RMSE: 1.431346, R^2: 0.407286\n",
      "[(1.2548377333671896, 'godsend'), (1.2270401652472538, 'lifesav'), (1.1898683943322512, 'unprotect'), (1.1801398060339165, 'miracl'), (1.173132512404964, 'excel'), (1.1246286174665407, 'charm'), (1.117680167322056, 'changer'), (1.0778325362321668, 'saver'), (1.0089482726482586, 'amaz'), (0.9794313679144251, 'fantast')]\n",
      "[(-1.016651838474159, 'discontinu'), (-1.0384430550800337, 'asap'), (-1.1053822867519572, 'poison'), (-1.1332424460197257, 'ineffect'), (-1.1527095545789092, 'bewar'), (-1.170234909119874, 'ruin'), (-1.2805880930344806, 'destroy'), (-1.4662239521672298, 'wast'), (-1.558418621391281, 'useless'), (-1.8465237586176022, 'disappoint')]\n"
     ]
    }
   ],
   "source": [
    "min_ngram = 1\n",
    "max_ngram = 1\n",
    "print(\"\\nRunning ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "train_data_features, test_data_features, vc = getNgramFeatures(min_ngram, max_ngram, df_train, df_test)\n",
    "print(train_data_features.shape)\n",
    "print(test_data_features.shape)\n",
    "\n",
    "train_features = hstack((train_data_features,train_onehotlabels))\n",
    "test_features = hstack((test_data_features,test_onehotlabels))\n",
    "\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "model = getLinearRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "#for c in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "#    getRidgeRegressionResults(c, train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "    \n",
    "CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "CoefNames.sort(reverse=True)\n",
    "print(CoefNames[:10])\n",
    "print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=2000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(164672, 2000)\n",
      "(49189, 2000)\n",
      "(164672, 2022)\n",
      "(49189, 2022)\n",
      "TRAIN: MSE: 5.983772, RMSE: 1.406381, R^2: 0.441940\n",
      "TEST: MSE: 6.103440, RMSE: 1.414071, R^2: 0.432745\n",
      "[(1.2061842240678777, 'excel'), (1.1764769513865894, 'chang life'), (1.0169398565104273, 'miracl'), (0.9769062887915049, 'fantast'), (0.9574720704956541, 'amaz'), (0.9507365439870675, 'high recommend'), (0.9353259416462608, 'life saver'), (0.9320162077147068, 'awesom'), (0.9037079305303402, 'grate'), (0.889025505156692, 'best')]\n",
      "[(-0.9997113788270053, 'yeast infect'), (-1.0754547038443087, 'ruin'), (-1.1755932056322864, 'not help'), (-1.1900776453012365, 'never take'), (-1.3134955536147335, 'not work'), (-1.4483739799079447, 'wast'), (-1.578825786203609, 'no relief'), (-1.719396783877792, 'disappoint'), (-1.8584969678205965, 'not recommend'), (-1.9717988666951756, 'not worth')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=2000, min_df=2,\n",
      "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(164672, 2000)\n",
      "(49189, 2000)\n",
      "(164672, 2022)\n",
      "(49189, 2022)\n",
      "TRAIN: MSE: 5.987782, RMSE: 1.406775, R^2: 0.441566\n",
      "TEST: MSE: 6.103885, RMSE: 1.414157, R^2: 0.432704\n",
      "[(1.9224130101548178, 'take birth'), (1.4410005421496614, 'side effect except'), (1.2038042663689925, 'excel'), (1.1657806253941767, 'chang life'), (1.0622799680487451, 'no weight gain'), (1.0604409817419778, 'birth control pill'), (1.0137172511569539, 'miracl'), (0.9744896089289277, 'fantast'), (0.9605437062102029, 'amaz'), (0.9539097552965863, 'high recommend')]\n",
      "[(-1.1663912320940413, 'not help'), (-1.1898433148735874, 'never take'), (-1.2183788057783398, 'effect except'), (-1.3188209554468284, 'not work'), (-1.4475686725288244, 'wast'), (-1.5883784953834805, 'no relief'), (-1.7117673374598357, 'disappoint'), (-1.7404774701668972, 'not recommend'), (-1.9284061355816733, 'take birth control'), (-1.9824715615083222, 'not worth')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=5000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(164672, 5000)\n",
      "(49189, 5000)\n",
      "(164672, 5022)\n",
      "(49189, 5022)\n",
      "TRAIN: MSE: 5.432758, RMSE: 1.369861, R^2: 0.493329\n",
      "TEST: MSE: 5.751928, RMSE: 1.390701, R^2: 0.465415\n",
      "[(1.7728176894508438, 'esteem'), (1.358707453434158, 'brilliant'), (1.1948866197479966, 'godsend'), (1.1418412138885887, 'lifesav'), (1.1277181944543784, 'excel'), (1.1271155294510986, 'zero side'), (1.107728073433079, 'life saver'), (1.0921793907571609, 'chang life'), (1.068625615528705, 'changer'), (1.0530287337859054, 'miracul')]\n",
      "[(-1.5046959165195013, 'no effect'), (-1.5488227765424039, 'no help'), (-1.5830471443819027, 'disappoint'), (-1.6407581051318978, 'no relief'), (-1.6421431687260788, 'not recommend'), (-1.6853555528617392, 'garbag'), (-1.7302369934870765, 'not worth'), (-1.731888977967854, 'absolut noth'), (-1.8378871271479933, 'self esteem'), (-2.1021101663153057, 'no improv')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=5000, min_df=2,\n",
      "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(164672, 5000)\n",
      "(49189, 5000)\n",
      "(164672, 5022)\n",
      "(49189, 5022)\n",
      "TRAIN: MSE: 5.444850, RMSE: 1.370617, R^2: 0.492201\n",
      "TEST: MSE: 5.755400, RMSE: 1.390690, R^2: 0.465092\n",
      "[(3.880995993063744, 'gain acn'), (3.5477997054542683, 'use birth control'), (2.7101865196744077, 'lot side effect'), (2.016703337090559, 'esteem'), (1.964999308665894, 'birth control method'), (1.833158705810014, 'gain no'), (1.8062026713456651, 'side effect whatsoev'), (1.7115974995846706, 'small price'), (1.5961605945235091, 'get side effect'), (1.5894797688363107, 'stori short')]\n",
      "[(-1.7306697791732528, 'not worth'), (-1.7370513186223304, 'absolut noth'), (-1.7441296417488246, 'restless leg syndrom'), (-1.7646395877341654, 'control method'), (-2.0716879055554656, 'self esteem'), (-2.1000183343746666, 'effect includ'), (-2.112636831860395, 'no improv'), (-2.6157367068650674, 'lot side'), (-3.520592655240884, 'use birth'), (-3.8598225197814573, 'weight gain acn')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=10000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(164672, 10000)\n",
      "(49189, 10000)\n",
      "(164672, 10022)\n",
      "(49189, 10022)\n",
      "TRAIN: MSE: 4.979155, RMSE: 1.337498, R^2: 0.535633\n",
      "TEST: MSE: 5.571717, RMSE: 1.376363, R^2: 0.482164\n",
      "[(2.914916982791774, 'sclerosi'), (1.998850641365103, 'esteem'), (1.5206141481153854, 'suicid ideat'), (1.3377189310670272, 'heav'), (1.3176026643548688, 'brilliant'), (1.2909015418968255, 'life saver'), (1.272281624546663, 'break out'), (1.2631609181177783, 'changer'), (1.25596106490121, 'bone densiti'), (1.1719246469685425, 'miracul')]\n",
      "[(-1.634542838298813, 'not worth'), (-1.6360846331778869, 'not recommend'), (-1.6464550732968102, 'pleas care'), (-1.6668255170355146, 'never recommend'), (-1.6737273576712566, 'no good'), (-1.8715822094666952, 'done noth'), (-1.9103308205598988, 'absolut noth'), (-2.0215280667554865, 'no improv'), (-2.130095406323486, 'self esteem'), (-2.77584901607514, 'multipl sclerosi')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=10000, min_df=2,\n",
      "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(164672, 10000)\n",
      "(49189, 10000)\n",
      "(164672, 10022)\n",
      "(49189, 10022)\n",
      "TRAIN: MSE: 4.988014, RMSE: 1.338356, R^2: 0.534807\n",
      "TEST: MSE: 5.579919, RMSE: 1.376928, R^2: 0.481402\n",
      "[(5.706142901180523, 'switch birth control'), (4.521198734223404, 'gain acn'), (4.369272772424341, 'swing not'), (3.658797983000715, 'rare side effect'), (3.5237353994802136, 'lot side effect'), (3.3709634570268046, 'weight gain gain'), (3.317230848901117, 'signific side'), (3.1800070731163523, 'side effect dizzi'), (3.0629937301671974, 'sclerosi'), (2.708799161504578, 'not birth control')]\n",
      "[(-3.0645336988667125, 'gain gain'), (-3.1630017610316763, 'get birth control'), (-3.177518837221413, 'sex drive gone'), (-3.2174128832202697, 'effect dizzi'), (-3.2598180792488245, 'signific side effect'), (-3.4417734629576593, 'lot side'), (-4.275750979894539, 'mood swing not'), (-4.423922110457841, 'rare side'), (-4.466746879472801, 'weight gain acn'), (-6.077050728240829, 'switch birth')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=20000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(164672, 20000)\n",
      "(49189, 20000)\n",
      "(164672, 20022)\n",
      "(49189, 20022)\n",
      "TRAIN: MSE: 4.322456, RMSE: 1.287365, R^2: 0.596878\n",
      "TEST: MSE: 5.481258, RMSE: 1.368649, R^2: 0.490571\n",
      "[(4.311548961969228, 'prostat hyperplasia'), (3.6197354434783464, 'natur throid'), (3.2387650440477596, 'uric'), (2.9487752372167555, 'sclerosi'), (2.86344738005207, 'magnesia'), (2.5423458249110182, 'suicid ideat'), (1.9847423608970896, 'like clock'), (1.936226092512393, 'appl cider'), (1.8915123749318086, 'ortho cyclen'), (1.8724749505885117, 'size amount')]\n",
      "[(-2.2623976209850154, 'no better'), (-2.308228900394419, 'clock work'), (-2.40248237434137, 'not impress'), (-2.525768866902213, 'ideat'), (-2.63869874826628, 'multipl sclerosi'), (-2.7324478413804623, 'milk magnesia'), (-2.8158257473837915, 'projectil vomit'), (-3.120558218517928, 'throid'), (-3.3158303903533324, 'uric acid'), (-4.643427946030308, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=20000, min_df=2,\n",
      "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(164672, 20000)\n",
      "(49189, 20000)\n",
      "(164672, 20022)\n",
      "(49189, 20022)\n",
      "TRAIN: MSE: 4.322601, RMSE: 1.287358, R^2: 0.596865\n",
      "TEST: MSE: 5.487567, RMSE: 1.369797, R^2: 0.489985\n",
      "[(5.88598603606264, 'mood swing headach'), (5.786551694297032, 'switch birth control'), (5.574356425386664, 'go lie'), (4.791338487589364, 'effect besid'), (4.376265423592885, 'swing not'), (4.328757556414619, 'natur throid'), (4.271973678377445, 'gain acn'), (4.032500510605973, 'put birth control'), (3.9269862431613065, 'provera shot'), (3.803707444000861, 'give side effect')]\n",
      "[(-3.7451263069497114, 'get birth control'), (-3.9258918149192317, 'throid'), (-3.974416965995182, 'rare side'), (-3.9886796899230395, 'put birth'), (-4.222406403200721, 'weight gain acn'), (-4.422586082580373, 'mood swing not'), (-4.552927585531066, 'not go lie'), (-4.745783546969341, 'side effect besid'), (-5.665875132417721, 'swing headach'), (-6.267723748377258, 'switch birth')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=30000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(164672, 30000)\n",
      "(49189, 30000)\n",
      "(164672, 30022)\n",
      "(49189, 30022)\n",
      "TRAIN: MSE: 3.757533, RMSE: 1.238507, R^2: 0.649564\n",
      "TEST: MSE: 5.532588, RMSE: 1.367198, R^2: 0.485801\n",
      "[(4.261131124976195, 'natur throid'), (3.583403312261175, 'prostat hyperplasia'), (3.0242287452691667, 'last ditch'), (2.6560272149979496, 'dysphor disord'), (2.4498719095770842, 'magnesia'), (2.259081236216927, 'size amount'), (2.18589674430277, 'atop'), (2.169268079625775, 'not zombi'), (2.13990848618606, 'suicid ideat'), (2.1083823211834747, 'fetal posit')]\n",
      "[(-2.467886413492052, 'sign stop'), (-2.472722697157308, 'yes help'), (-2.493525021740531, 'may good'), (-2.5367997773481665, 'ditch effort'), (-2.538633350907105, 'took direct'), (-2.5690379868744486, 'milk magnesia'), (-2.713478777807937, 'scam'), (-3.1707523817751744, 'premenstru dysphor'), (-3.8082880882167127, 'throid'), (-4.12664121663527, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=30000, min_df=2,\n",
      "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(164672, 30000)\n",
      "(49189, 30000)\n",
      "(164672, 30022)\n",
      "(49189, 30022)\n",
      "TRAIN: MSE: 3.778656, RMSE: 1.240087, R^2: 0.647594\n",
      "TEST: MSE: 5.529739, RMSE: 1.368099, R^2: 0.486065\n",
      "[(6.47250130398787, 'pregnanc side'), (6.17734036830104, 'immedi side'), (5.931007273831835, 'strang side'), (5.8132697645172575, 'harsh side'), (5.426072049238533, 'mood swing headach'), (5.352557580781898, 'provera shot'), (5.209881292674419, 'control anyon'), (5.1911266797635225, 'care physician'), (5.001706936701875, 'put birth control'), (5.001118975984901, 'side effect bother')]\n",
      "[(-4.974795063568081, 'longer avail'), (-5.000683139725921, 'harsh side effect'), (-5.024369845912632, 'effect bother'), (-5.164796967830902, 'mouth drink'), (-5.370552905098018, 'birth control anyon'), (-5.417157708747684, 'swing headach'), (-5.8653687180257, 'primari care physician'), (-6.3463349832615314, 'strang side effect'), (-6.705697696354573, 'immedi side effect'), (-6.791147747555291, 'pregnanc side effect')]\n"
     ]
    }
   ],
   "source": [
    "## test set 0.23\n",
    "for numFeatures in [2000,5000,10000,20000,30000]:\n",
    "    for max_ngram in [2,3]:    \n",
    "        min_ngram = 1\n",
    "\n",
    "        print(\"\\nRunning ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "        train_data_features, test_data_features, vc = getNgramFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "        print(train_data_features.shape)\n",
    "        print(test_data_features.shape)\n",
    "\n",
    "        train_features = hstack((train_data_features,train_onehotlabels))\n",
    "        test_features = hstack((test_data_features,test_onehotlabels))\n",
    "\n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        model = getLinearRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        #for c in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        #    getRidgeRegressionResults(c, train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "        CoefNames.sort(reverse=True)\n",
    "        print(CoefNames[:10])\n",
    "        print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=2000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 2000)\n",
      "(10694, 2000)\n",
      "(203167, 2022)\n",
      "(10694, 2022)\n",
      "TRAIN: MSE: 5.978909, RMSE: 1.406415, R^2: 0.442427\n",
      "TEST: MSE: 6.099793, RMSE: 1.412417, R^2: 0.439327\n",
      "[(1.235084766068817, 'lifesav'), (1.2242960264942118, 'excel'), (1.1875093267807746, 'chang life'), (1.1136560939600213, 'life saver'), (1.0368774516656638, 'miracl'), (1.0026266972024114, 'fantast'), (0.9495318666355569, 'amaz'), (0.9433275448639252, 'high recommend'), (0.9217980440952729, 'grate'), (0.9182887934915263, 'awesom')]\n",
      "[(-1.0435589077790952, 'ruin'), (-1.1762363565866425, 'not help'), (-1.2167406256271975, 'never take'), (-1.3079002886553246, 'not work'), (-1.440213559646672, 'wast'), (-1.4495971323910481, 'no effect'), (-1.5995040163961094, 'no relief'), (-1.6987586308440412, 'disappoint'), (-1.8183960683734366, 'not recommend'), (-1.9782266380859233, 'not worth')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=5000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 5000)\n",
      "(10694, 5000)\n",
      "(203167, 5022)\n",
      "(10694, 5022)\n",
      "TRAIN: MSE: 5.465571, RMSE: 1.372284, R^2: 0.490299\n",
      "TEST: MSE: 5.683220, RMSE: 1.385749, R^2: 0.477617\n",
      "[(1.6314815844869164, 'esteem'), (1.3460716540414641, 'life saver'), (1.2716378943901778, 'godsend'), (1.2582501126775028, 'brilliant'), (1.196964158719415, 'zero side'), (1.1609654282002626, 'lifesav'), (1.1518481515259313, 'excel'), (1.134694236900499, 'roller coaster'), (1.099063522504751, 'chang life'), (1.059127262584469, 'changer')]\n",
      "[(-1.5069987470779862, 'no effect'), (-1.5345099867938468, 'no help'), (-1.5823886889280212, 'garbag'), (-1.5832718118920714, 'disappoint'), (-1.58872796160812, 'self esteem'), (-1.5954745055839952, 'not recommend'), (-1.6209911438824742, 'no relief'), (-1.6686831935541002, 'absolut noth'), (-1.6867149701357436, 'not worth'), (-2.1423683269495357, 'no improv')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=10000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 10000)\n",
      "(10694, 10000)\n",
      "(203167, 10022)\n",
      "(10694, 10022)\n",
      "TRAIN: MSE: 5.031994, RMSE: 1.341593, R^2: 0.530733\n",
      "TEST: MSE: 5.458434, RMSE: 1.370833, R^2: 0.498278\n",
      "[(2.8202366417267486, 'sclerosi'), (1.7856512040576227, 'esteem'), (1.4855124565714342, 'suicid ideat'), (1.4613944172866984, 'life saver'), (1.3392162907580265, 'roller coaster'), (1.2163231229924503, 'changer'), (1.1972707036199628, 'godsend'), (1.183070379388074, 'brilliant'), (1.1725756467053934, 'no itch'), (1.169853455956449, 'miracul')]\n",
      "[(-1.6253663432177037, 'not recommend'), (-1.627312613518149, 'not worth'), (-1.7064882767657363, 'never recommend'), (-1.7093311464603325, 'no good'), (-1.7228796555662909, 'ideat'), (-1.7792670765989813, 'self esteem'), (-1.8679055364526878, 'absolut noth'), (-1.9000888249111374, 'done noth'), (-2.0606178658814502, 'no improv'), (-2.5827171018981945, 'multipl sclerosi')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=20000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 20000)\n",
      "(10694, 20000)\n",
      "(203167, 20022)\n",
      "(10694, 20022)\n",
      "TRAIN: MSE: 4.417069, RMSE: 1.295319, R^2: 0.588079\n",
      "TEST: MSE: 5.338422, RMSE: 1.360904, R^2: 0.509309\n",
      "[(4.5700761782313615, 'natur throid'), (3.8850109728191744, 'magnesia'), (3.7977718326395586, 'prostat hyperplasia'), (2.817309238954841, 'uric'), (2.5971659209338465, 'sclerosi'), (2.293765355284702, 'like clock'), (2.2696645210852266, 'suicid ideat'), (1.8364871339946054, 'guinea'), (1.820567069766563, 'ortho cyclen'), (1.592929484368733, 'size amount')]\n",
      "[(-2.2953000018457623, 'multipl sclerosi'), (-2.3255265685823234, 'no better'), (-2.3358362795978835, 'not impress'), (-2.4067643312145375, 'ideat'), (-2.4644824549238993, 'no benefit'), (-2.4827951879057046, 'clock work'), (-2.877493143742902, 'uric acid'), (-3.7642741643876745, 'milk magnesia'), (-3.999981284721568, 'benign prostat'), (-4.028886018188924, 'throid')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=25000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 25000)\n",
      "(10694, 25000)\n",
      "(203167, 25022)\n",
      "(10694, 25022)\n",
      "TRAIN: MSE: 4.156768, RMSE: 1.274131, R^2: 0.612354\n",
      "TEST: MSE: 5.309235, RMSE: 1.358226, R^2: 0.511992\n",
      "[(4.5388360459263275, 'natur throid'), (4.219053020868602, 'prostat hyperplasia'), (3.48417039068752, 'magnesia'), (2.4476123867195434, 'tessalon perl'), (2.3063260308865328, 'sclerosi'), (2.2583669290515376, 'suicid ideat'), (2.228507453604531, 'marrow'), (2.2169776246471438, 'tri nessa'), (2.148242611917589, 'john wort'), (2.0908966906399318, 'folic')]\n",
      "[(-2.2504244836715586, 'perl'), (-2.2884973171783045, 'generalis anxieti'), (-2.4064365109372834, 'no better'), (-2.4150914907407577, 'not impress'), (-2.523471695720235, 'ideat'), (-2.533460562445925, 'no benefit'), (-2.5353185687276403, 'bone marrow'), (-3.6020856042409353, 'milk magnesia'), (-4.015107494887664, 'throid'), (-4.464449528406011, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=30000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 30000)\n",
      "(10694, 30000)\n",
      "(203167, 30022)\n",
      "(10694, 30022)\n",
      "TRAIN: MSE: 3.904232, RMSE: 1.252603, R^2: 0.635904\n",
      "TEST: MSE: 5.291139, RMSE: 1.354496, R^2: 0.513655\n",
      "[(4.771217787421024, 'natur throid'), (4.149689250081667, 'prostat hyperplasia'), (3.4516445443698824, 'dysphor disord'), (3.2706771630887777, 'magnesia'), (2.4836171981073654, 'tri nessa'), (2.232178482804911, 'maxalt mlt'), (2.1160393326479046, 'like clock'), (2.089679072558727, 'fetal posit'), (2.04901449177639, 'tessalon perl'), (2.034898865027971, 'suicid ideat')]\n",
      "[(-2.4384407726210116, 'scam'), (-2.4410883621990918, 'put depress'), (-2.4585243823484313, 'nessa'), (-2.461830389079635, 'right also'), (-2.474226369851272, 'may good'), (-2.7464826843019603, 'no benefit'), (-2.8384373227886357, 'premenstru dysphor'), (-3.370020207407278, 'milk magnesia'), (-4.265918052115546, 'throid'), (-4.4164410049223, 'benign prostat')]\n"
     ]
    }
   ],
   "source": [
    "# Test set 0.05\n",
    "for numFeatures in [2000,5000,10000,20000,25000,30000]:\n",
    "    max_ngram = 2    \n",
    "    min_ngram = 1\n",
    "\n",
    "    print(\"\\nRunning ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "    train_data_features, test_data_features, vc = getNgramFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "    print(train_data_features.shape)\n",
    "    print(test_data_features.shape)\n",
    "\n",
    "    train_features = hstack((train_data_features,train_onehotlabels))\n",
    "    test_features = hstack((test_data_features,test_onehotlabels))\n",
    "\n",
    "    print(train_features.shape)\n",
    "    print(test_features.shape)\n",
    "\n",
    "    model = getLinearRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "    #for c in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    #    getRidgeRegressionResults(c, train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "    CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "    CoefNames.sort(reverse=True)\n",
    "    print(CoefNames[:10])\n",
    "    print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=35000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35022)\n",
      "(10694, 35022)\n",
      "TRAIN: MSE: 3.668728, RMSE: 1.231257, R^2: 0.657867\n",
      "TEST: MSE: 5.278440, RMSE: 1.351960, R^2: 0.514823\n",
      "[(4.414736728082629, 'pump inhibitor'), (4.319087207076994, 'prostat hyperplasia'), (4.127861036753822, 'natur throid'), (4.099887717949005, 'magnesia'), (3.4834169187590667, 'dysphor disord'), (3.390686534289931, 'tri nessa'), (3.033328362171943, 'bleed complet'), (2.8121862856093593, 'ice cube'), (2.5335598534432777, 'estrin'), (2.4484896835399255, 'folic')]\n",
      "[(-2.648485279927639, 'premenstru dysphor'), (-2.7002693350538225, 'right also'), (-2.771900166937557, 'littlest'), (-2.846103563785615, 'no benefit'), (-3.0598119016713463, 'cube'), (-3.3016853426657775, 'nessa'), (-3.7645305748969116, 'throid'), (-4.0985517223151, 'milk magnesia'), (-4.902642436520958, 'benign prostat'), (-5.3889146782746264, 'proton pump')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=40000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 40000)\n",
      "(10694, 40000)\n",
      "(203167, 40022)\n",
      "(10694, 40022)\n",
      "TRAIN: MSE: 3.440472, RMSE: 1.209801, R^2: 0.679153\n",
      "TEST: MSE: 5.285699, RMSE: 1.349810, R^2: 0.514155\n",
      "[(4.390918693498113, 'prostat hyperplasia'), (4.378289057123059, 'natur throid'), (3.825587745055109, 'magnesia'), (3.412291656269844, 'bleed complet'), (2.9236719359955283, 'dysphor disord'), (2.737842644225568, 'folic'), (2.727179993360357, 'ice cube'), (2.6248827431088775, 'fit pal'), (2.4927970191507582, 'shield'), (2.403534806507181, 'lens')]\n",
      "[(-2.7536174268743903, 'no better'), (-2.8231084630534524, 'rate low'), (-2.829968820443301, 'littlest'), (-3.077353863551626, 'cube'), (-3.082489716800065, 'connect dot'), (-3.115549657083955, 'no benefit'), (-3.548686022163567, 'blue shield'), (-3.724767356925156, 'milk magnesia'), (-3.8628748121564005, 'throid'), (-5.051071558068767, 'benign prostat')]\n"
     ]
    }
   ],
   "source": [
    "# Test set 0.05\n",
    "for numFeatures in [35000, 40000]:\n",
    "    max_ngram = 2    \n",
    "    min_ngram = 1\n",
    "\n",
    "    print(\"\\nRunning ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "    train_data_features, test_data_features, vc = getNgramFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "    print(train_data_features.shape)\n",
    "    print(test_data_features.shape)\n",
    "\n",
    "    train_features = hstack((train_data_features,train_onehotlabels))\n",
    "    test_features = hstack((test_data_features,test_onehotlabels))\n",
    "\n",
    "    print(train_features.shape)\n",
    "    print(test_features.shape)\n",
    "\n",
    "    model = getLinearRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "    #for c in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    #    getRidgeRegressionResults(c, train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "    CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "    CoefNames.sort(reverse=True)\n",
    "    print(CoefNames[:10])\n",
    "    print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=20000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 20000)\n",
      "(10694, 20000)\n",
      "(203167, 20938)\n",
      "(10694, 20938)\n",
      "(203167, 20939)\n",
      "(10694, 20939)\n",
      "TRAIN: MSE: 4.251992, RMSE: 1.280461, R^2: 0.603473\n",
      "TEST: MSE: 5.220429, RMSE: 1.350555, R^2: 0.520155\n",
      "[(3.7619246016471086, 'natur throid'), (3.7480817745744566, 'magnesia'), (3.54288436369591, 'prostat hyperplasia'), (2.8896377464974377, 'uric'), (2.669328112506924, 'sclerosi'), (2.5225885049752437, 'like clock'), (2.2165448801741694, 'suicid ideat'), (1.7902040425410233, 'john wort'), (1.637034289539028, 'guinea'), (1.6235346855424135, 'ortho cyclen')]\n",
      "[(-2.284848958475718, 'multipl sclerosi'), (-2.326567420790687, 'not impress'), (-2.3627738366065962, 'no better'), (-2.37748356960608, 'ideat'), (-2.550881391985835, 'no benefit'), (-2.727760672703442, 'clock work'), (-2.9768751669725875, 'uric acid'), (-3.4252213389006414, 'throid'), (-3.7215390675229703, 'milk magnesia'), (-3.7895214403882687, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=20000, min_df=2,\n",
      "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 20000)\n",
      "(10694, 20000)\n",
      "(203167, 20938)\n",
      "(10694, 20938)\n",
      "(203167, 20939)\n",
      "(10694, 20939)\n",
      "TRAIN: MSE: 4.254213, RMSE: 1.280864, R^2: 0.603266\n",
      "TEST: MSE: 5.212506, RMSE: 1.350575, R^2: 0.520883\n",
      "[(6.106233985809729, 'mood swing headach'), (5.21490311998008, 'switch birth control'), (4.560501602108316, 'swing not'), (4.522253457979067, 'gain acn'), (4.34992074433119, 'magnesia'), (4.084015384489425, 'put birth control'), (3.9421648578105764, 'use birth control'), (3.866604236601718, 'go lie'), (3.75647605562273, 'rare side effect'), (3.7259345443749474, 'short amount time')]\n",
      "[(-3.8888946948200744, 'get birth control'), (-3.9807782864367005, 'previous birth'), (-3.982475425873281, 'put birth'), (-4.111943515239094, 'use birth'), (-4.1655342725887, 'milk magnesia'), (-4.383308480784468, 'rare side'), (-4.4284980442265445, 'weight gain acn'), (-4.594847166560736, 'mood swing not'), (-5.7768690641107785, 'switch birth'), (-5.902484715191425, 'swing headach')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=25000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 25000)\n",
      "(10694, 25000)\n",
      "(203167, 25938)\n",
      "(10694, 25938)\n",
      "(203167, 25939)\n",
      "(10694, 25939)\n",
      "TRAIN: MSE: 4.000093, RMSE: 1.259540, R^2: 0.626965\n",
      "TEST: MSE: 5.190206, RMSE: 1.347915, R^2: 0.522933\n",
      "[(4.007027971505997, 'prostat hyperplasia'), (3.8625467286124735, 'natur throid'), (3.5218810307618935, 'magnesia'), (2.7496842025254833, 'john wort'), (2.5347144183816446, 'sclerosi'), (2.441609707911157, 'tessalon perl'), (2.33294870212617, 'marrow'), (2.1428166432028313, 'suicid ideat'), (2.114913690514542, 'tri nessa'), (2.0174050729833373, 'like clock')]\n",
      "[(-2.361658428881774, 'breaker'), (-2.3690893588380657, 'not impress'), (-2.431858499146445, 'ideat'), (-2.4369756584487625, 'no better'), (-2.455168633781127, 'projectil vomit'), (-2.46187796856063, 'bone marrow'), (-2.614743927939468, 'no benefit'), (-3.4831545354691293, 'throid'), (-3.6911623095578516, 'milk magnesia'), (-4.227637013140247, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=25000, min_df=2,\n",
      "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 25000)\n",
      "(10694, 25000)\n",
      "(203167, 25938)\n",
      "(10694, 25938)\n",
      "(203167, 25939)\n",
      "(10694, 25939)\n",
      "TRAIN: MSE: 3.998696, RMSE: 1.259240, R^2: 0.627095\n",
      "TEST: MSE: 5.203555, RMSE: 1.349928, R^2: 0.521706\n",
      "[(6.62497726900891, 'immedi side'), (5.973880487655191, 'mood swing headach'), (4.988565853491229, 'put birth control'), (4.760392100684818, 'scari side'), (4.643307636045932, 'care physician'), (4.642772266197376, 'blood pressur year'), (4.58498280313329, 'short amount time'), (4.5698539405494, 'magnesia'), (4.463082119373496, 'go lie'), (4.28683767901015, 'provera shot')]\n",
      "[(-4.270705226456224, 'rare side'), (-4.502123150505249, 'milk magnesia'), (-4.596032800907727, 'benign prostat'), (-4.65537174762081, 'pressur year'), (-4.704187189242305, 'put birth'), (-4.711835619123672, 'switch birth'), (-5.069307949268868, 'scari side effect'), (-5.1671830509476955, 'primari care physician'), (-5.688688104222316, 'swing headach'), (-7.590122450218754, 'immedi side effect')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=30000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 30000)\n",
      "(10694, 30000)\n",
      "(203167, 30938)\n",
      "(10694, 30938)\n",
      "(203167, 30939)\n",
      "(10694, 30939)\n",
      "TRAIN: MSE: 3.754560, RMSE: 1.238261, R^2: 0.649862\n",
      "TEST: MSE: 5.187375, RMSE: 1.345298, R^2: 0.523193\n",
      "[(4.204125184693774, 'natur throid'), (3.9384587913435665, 'prostat hyperplasia'), (3.793417136500396, 'dysphor disord'), (3.4513350911714515, 'magnesia'), (2.4847428516206085, 'tri nessa'), (2.456297550651245, 'john wort'), (2.3646934183258934, 'like clock'), (2.206648767098892, 'maxalt mlt'), (2.0796756853333087, 'tessalon perl'), (2.0070652761123178, 'fetal posit')]\n",
      "[(-2.4084133624495445, 'yes help'), (-2.408624622566545, 'may good'), (-2.4858839155644943, 'no better'), (-2.4929968403388783, 'right also'), (-2.620037776990059, 'clock work'), (-2.8401970382471546, 'no benefit'), (-3.1958359843716595, 'premenstru dysphor'), (-3.6016700317031236, 'milk magnesia'), (-3.889576255128796, 'throid'), (-4.09738009937164, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=30000, min_df=2,\n",
      "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 30000)\n",
      "(10694, 30000)\n",
      "(203167, 30938)\n",
      "(10694, 30938)\n",
      "(203167, 30939)\n",
      "(10694, 30939)\n",
      "TRAIN: MSE: 3.769939, RMSE: 1.239474, R^2: 0.648428\n",
      "TEST: MSE: 5.201537, RMSE: 1.347076, R^2: 0.521891\n",
      "[(6.861911860416084, 'immedi side'), (5.823192916229602, 'strang side'), (5.807293418240091, 'harsh side'), (5.626317211037037, 'mood swing headach'), (5.102156671724775, 'care physician'), (4.868366495801799, 'side effect bother'), (4.769091366969565, 'scari side'), (4.698809978311337, 'st john wort'), (4.622841112631496, 'short amount time'), (4.5200136224152985, 'swing not')]\n",
      "[(-4.5251854760992325, 'mood swing not'), (-4.5945402295102244, 'switch birth'), (-4.7817615094723775, 'effect bother'), (-4.964936582126775, 'harsh side effect'), (-5.119463316841861, 'scari side effect'), (-5.409777861963519, 'primari care physician'), (-5.5909665973423905, 'swing headach'), (-5.829388986266322, 'st john'), (-6.035668814498659, 'strang side effect'), (-7.878403376927478, 'immedi side effect')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=35000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35938)\n",
      "(10694, 35938)\n",
      "(203167, 35939)\n",
      "(10694, 35939)\n",
      "TRAIN: MSE: 3.528651, RMSE: 1.217369, R^2: 0.670930\n",
      "TEST: MSE: 5.178760, RMSE: 1.343268, R^2: 0.523985\n",
      "[(4.3252471194933655, 'magnesia'), (4.3119842060379305, 'pump inhibitor'), (4.0220205692010005, 'prostat hyperplasia'), (3.7254015487555256, 'dysphor disord'), (3.4495525259792688, 'natur throid'), (3.4204928442243787, 'tri nessa'), (2.898977266848673, 'bleed complet'), (2.7153031892859576, 'ice cube'), (2.4824204658413382, 'estrin'), (2.4313966452033813, 'folic')]\n",
      "[(-2.609888132884839, 'no better'), (-2.6963433521393037, 'right also'), (-2.9289642812382723, 'no benefit'), (-2.9704348114836665, 'premenstru dysphor'), (-3.019945664132607, 'cube'), (-3.1753100400079433, 'nessa'), (-3.297921718035009, 'throid'), (-4.445681790833904, 'milk magnesia'), (-4.559463976685593, 'benign prostat'), (-5.169258775005369, 'proton pump')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=35000, min_df=2,\n",
      "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35938)\n",
      "(10694, 35938)\n",
      "(203167, 35939)\n",
      "(10694, 35939)\n",
      "TRAIN: MSE: 3.531982, RMSE: 1.217479, R^2: 0.670619\n",
      "TEST: MSE: 5.209002, RMSE: 1.344425, R^2: 0.521205\n",
      "[(7.073981296812098, 'daili panic attack'), (6.992328956760232, 'mood swing headach'), (6.784853876566327, 'immedi side'), (6.7072763670412225, 'harsh side'), (6.04179871018128, 'scari side'), (5.648053692027547, 'short amount time'), (5.530620784754394, 'strang side'), (5.303757338705987, 'side effect bother'), (5.127646765203579, 'care physician'), (5.07175456793532, 'gain nausea')]\n",
      "[(-5.125854290617337, 'suffer cystic acn'), (-5.145461377710186, 'st john'), (-5.262502694658558, 'primari care physician'), (-5.325555696296169, 'weight gain nausea'), (-5.766800574394532, 'strang side effect'), (-5.833067662946756, 'harsh side effect'), (-6.374329715012271, 'scari side effect'), (-6.865794965604433, 'swing headach'), (-7.568298722059336, 'daili panic'), (-7.895644975337215, 'immedi side effect')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=40000, min_df=2,\n",
      "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 40000)\n",
      "(10694, 40000)\n",
      "(203167, 40938)\n",
      "(10694, 40938)\n",
      "(203167, 40939)\n",
      "(10694, 40939)\n",
      "TRAIN: MSE: 3.308389, RMSE: 1.196247, R^2: 0.691471\n",
      "TEST: MSE: 5.182842, RMSE: 1.340764, R^2: 0.523610\n",
      "[(4.268784586812004, 'prostat hyperplasia'), (3.8470308346040425, 'magnesia'), (3.7063105144830875, 'natur throid'), (3.2863514737306376, 'bleed complet'), (3.1136201927818057, 'dysphor disord'), (2.6314178064068416, 'folic'), (2.5503052598059273, 'ice cube'), (2.4963217953324204, 'fit pal'), (2.365811858440317, 'lens'), (2.342570284161853, 'revolv')]\n",
      "[(-2.80608030407393, 'no better'), (-2.9398868286233726, 'rate low'), (-2.950825005117453, 'cube'), (-3.019149269412517, 'amox clav'), (-3.118082058836824, 'connect dot'), (-3.200689398990112, 'no benefit'), (-3.4496252441362576, 'throid'), (-3.6718300354782962, 'blue shield'), (-3.8526438443100126, 'milk magnesia'), (-4.890865364003667, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=40000, min_df=2,\n",
      "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(203167, 40000)\n",
      "(10694, 40000)\n",
      "(203167, 40938)\n",
      "(10694, 40938)\n",
      "(203167, 40939)\n",
      "(10694, 40939)\n",
      "TRAIN: MSE: 3.318774, RMSE: 1.196455, R^2: 0.690502\n",
      "TEST: MSE: 5.195204, RMSE: 1.341851, R^2: 0.522473\n",
      "[(7.910800241178462, 'strang side'), (7.3033532133788155, 'harsh side'), (6.569458184501222, 'mood swing headach'), (6.433272435127912, 'scari side'), (6.168089846711573, 'short amount time'), (6.023680141754475, 'immedi side'), (5.82859606648316, 'took empti stomach'), (5.730995328050416, 'syndrom constip'), (5.612626012309467, 'viral load went'), (5.500000959994877, 'daili panic attack')]\n",
      "[(-5.395462383631506, 'took empti'), (-5.454064499870378, 'worst yeast infect'), (-5.687210519303532, 'bowel syndrom constip'), (-6.040100579824426, 'load went'), (-6.159088063898686, 'daili panic'), (-6.350170373909803, 'harsh side effect'), (-6.529496368815913, 'swing headach'), (-6.88329643965891, 'scari side effect'), (-7.293916014656073, 'immedi side effect'), (-8.127000150591877, 'strang side effect')]\n"
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "for numFeatures in [20000, 25000, 30000, 35000, 40000]:\n",
    "    for max_ngram in [2, 3]: \n",
    "        min_ngram = 1\n",
    "\n",
    "        print(\"\\nRunning ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "        train_data_features, test_data_features, vc = getNgramFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "        print(train_data_features.shape)\n",
    "        print(test_data_features.shape)\n",
    "\n",
    "        train_features = hstack((train_data_features,train_onehotlabels))\n",
    "        test_features = hstack((test_data_features,test_onehotlabels))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "        test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        model = getLinearRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        #for c in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        #    getRidgeRegressionResults(c, train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "        CoefNames.sort(reverse=True)\n",
    "        print(CoefNames[:10])\n",
    "        print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=20000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 20000)\n",
      "(10694, 20000)\n",
      "(203167, 20938)\n",
      "(10694, 20938)\n",
      "(203167, 20939)\n",
      "(10694, 20939)\n",
      "TRAIN: MSE: 3.800098, RMSE: 1.238629, R^2: 0.645615\n",
      "TEST: MSE: 4.733297, RMSE: 1.309550, R^2: 0.564930\n",
      "[(17.041855943532195, 'magnesia'), (16.343852993657823, 'natur throid'), (16.2912740065747, 'prostat hyperplasia'), (13.700268058172043, 'uric'), (13.279316863605814, 'sclerosi'), (12.212045890461622, 'john wort'), (11.966774549857664, 'suicid ideat'), (10.800236319740362, 'like clock'), (9.42413907064617, 'go lie'), (8.724798132969003, 'bi polar')]\n",
      "[(-10.228985785482111, 'not worth'), (-10.558572619141023, 'multipl sclerosi'), (-10.774260630054584, 'not impress'), (-11.484012506117004, 'clock work'), (-12.781700851405466, 'uric acid'), (-12.925289207308152, 'projectil vomit'), (-13.755196085619112, 'ideat'), (-13.757367954688736, 'throid'), (-15.795081059861046, 'milk magnesia'), (-17.319859206979377, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=20000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 20000)\n",
      "(10694, 20000)\n",
      "(203167, 20938)\n",
      "(10694, 20938)\n",
      "(203167, 20939)\n",
      "(10694, 20939)\n",
      "TRAIN: MSE: 3.799406, RMSE: 1.238632, R^2: 0.645680\n",
      "TEST: MSE: 4.712072, RMSE: 1.306324, R^2: 0.566881\n",
      "[(37.29031450926473, 'mood swing headach'), (28.035829225483226, 'not birth control'), (24.02380745339933, 'magnesia'), (23.908004683911514, 'tri lo sprintec'), (23.464213194605502, 'gain acn'), (22.744362096092303, 'put birth control'), (22.045070157444073, 'terribl side'), (20.873846411081246, 'provera shot'), (20.678472343036542, 'weight gain gain'), (19.477622893370256, 'swing not')]\n",
      "[(-19.487104533172054, 'mood swing not'), (-19.764643513401385, 'use birth'), (-20.731636674253295, 'switch birth'), (-22.110059259631573, 'terribl side effect'), (-22.28690007618562, 'milk magnesia'), (-22.610297733866883, 'put birth'), (-22.715876979036093, 'weight gain acn'), (-23.638937141451738, 'not birth'), (-24.548962752075017, 'lo sprintec'), (-35.62377968751087, 'swing headach')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=25000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 25000)\n",
      "(10694, 25000)\n",
      "(203167, 25938)\n",
      "(10694, 25938)\n",
      "(203167, 25939)\n",
      "(10694, 25939)\n",
      "TRAIN: MSE: 3.552582, RMSE: 1.217908, R^2: 0.668698\n",
      "TEST: MSE: 4.711584, RMSE: 1.307392, R^2: 0.566926\n",
      "[(20.345872606917695, 'magnesia'), (18.908437963676153, 'natur throid'), (17.977813293727202, 'prostat hyperplasia'), (16.60670601368079, 'marrow'), (13.324022718432088, 'folic'), (13.164795873299855, 'tessalon perl'), (12.960235356374373, 'sclerosi'), (12.9158504568514, 'john wort'), (12.572457989356327, 'suicid ideat'), (10.792096499193246, 'pregnant second')]\n",
      "[(-11.250469765245882, 'not impress'), (-11.280637872993054, 'ale'), (-11.654977784492896, 'clock work'), (-11.833445175623815, 'perl'), (-13.993531516927744, 'projectil vomit'), (-14.706411730453382, 'ideat'), (-16.03135945961591, 'throid'), (-16.177359590705024, 'bone marrow'), (-18.397440890987397, 'benign prostat'), (-20.289193951459538, 'milk magnesia')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=25000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 25000)\n",
      "(10694, 25000)\n",
      "(203167, 25938)\n",
      "(10694, 25938)\n",
      "(203167, 25939)\n",
      "(10694, 25939)\n",
      "TRAIN: MSE: 3.548514, RMSE: 1.217227, R^2: 0.669077\n",
      "TEST: MSE: 4.702899, RMSE: 1.306490, R^2: 0.567725\n",
      "[(40.78920260644827, 'immedi side'), (39.545044060820096, 'mood swing headach'), (32.037565435280825, 'blood pressur year'), (30.200127848973015, 'not birth control'), (29.47992360708358, 'provera shot'), (28.408713934012614, 'care physician'), (27.25525235344778, 'magnesia'), (26.424935689138252, 'put birth control'), (25.988467043087162, 'scari side'), (25.96491504527443, 'terribl side')]\n",
      "[(-25.443705434754936, 'not birth'), (-25.714139196361028, 'put birth'), (-26.18633559682932, 'milk magnesia'), (-26.24509124709363, 'terribl side effect'), (-26.546869144767726, 'depo provera shot'), (-26.555791531388394, 'scari side effect'), (-30.594546561107617, 'primari care physician'), (-31.61075450630628, 'pressur year'), (-37.53876504675036, 'swing headach'), (-44.90437336970212, 'immedi side effect')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=30000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 30000)\n",
      "(10694, 30000)\n",
      "(203167, 30938)\n",
      "(10694, 30938)\n",
      "(203167, 30939)\n",
      "(10694, 30939)\n",
      "TRAIN: MSE: 3.321771, RMSE: 1.196935, R^2: 0.690223\n",
      "TEST: MSE: 4.686358, RMSE: 1.304521, R^2: 0.569245\n",
      "[(18.37104343924102, 'dysphor disord'), (18.21023399496174, 'prostat hyperplasia'), (16.670693586845953, 'natur throid'), (13.316982770971276, 'magnesia'), (12.548328208173642, 'marrow'), (12.034630852063993, 'john wort'), (11.867428076191509, 'tessalon perl'), (11.747348636284732, 'pregnant second'), (11.687939799937816, 'suicid ideat'), (11.100057944608235, 'like clock')]\n",
      "[(-11.907299755203097, 'bone marrow'), (-12.179886135087965, 'clock work'), (-12.181186863214064, 'littlest'), (-12.644284941854691, 'put depress'), (-12.750991131676004, 'premenstru dysphor'), (-13.217198411495167, 'ideat'), (-13.304507271336997, 'milk magnesia'), (-13.968020273881617, 'projectil vomit'), (-14.165437090592796, 'throid'), (-19.41444127673707, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=30000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 30000)\n",
      "(10694, 30000)\n",
      "(203167, 30938)\n",
      "(10694, 30938)\n",
      "(203167, 30939)\n",
      "(10694, 30939)\n",
      "TRAIN: MSE: 3.325939, RMSE: 1.197182, R^2: 0.689834\n",
      "TEST: MSE: 4.719657, RMSE: 1.306068, R^2: 0.566184\n",
      "[(42.322751292851095, 'immedi side'), (40.48515525598031, 'mood swing headach'), (34.01267363549635, 'not birth control'), (32.53412965099908, 'st john wort'), (32.18314088584002, 'look forward see'), (32.14041666110252, 'harsh side'), (31.545044609521288, 'provera shot'), (30.939285373723273, 'blood pressur year'), (29.10556008472824, 'care physician'), (28.380157367394474, 'strang side')]\n",
      "[(-27.80744876394529, 'depo provera shot'), (-28.444365526637007, 'strang side effect'), (-28.689057389885257, 'forward see'), (-28.726753092029227, 'terribl side effect'), (-28.962455754469087, 'not birth'), (-30.226308828443425, 'primari care physician'), (-30.44286975583381, 'pressur year'), (-39.138023128713584, 'swing headach'), (-39.185024425248756, 'st john'), (-46.46193105615635, 'immedi side effect')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=35000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35938)\n",
      "(10694, 35938)\n",
      "(203167, 35939)\n",
      "(10694, 35939)\n",
      "TRAIN: MSE: 3.106133, RMSE: 1.176421, R^2: 0.710332\n",
      "TEST: MSE: 4.652426, RMSE: 1.303006, R^2: 0.572364\n",
      "[(18.947646069114654, 'pump inhibitor'), (17.992210485618052, 'dysphor disord'), (17.101827469552912, 'prostat hyperplasia'), (16.908157870508415, 'magnesia'), (15.826199534617, 'ice cube'), (14.255221707648403, 'bleed complet'), (13.859279361363459, 'folic'), (13.771739031483552, 'natur throid'), (12.781669145332604, 'tri nessa'), (12.557497345775875, 'marrow')]\n",
      "[(-12.504281441641268, 'say wait'), (-12.699503178416922, 'put depress'), (-13.535840725983538, 'clock work'), (-14.077673177997365, 'cyclin'), (-14.671977679344664, 'littlest'), (-14.95897649828266, 'projectil vomit'), (-17.099141960949353, 'milk magnesia'), (-17.336358648032142, 'cube'), (-19.179623479751577, 'benign prostat'), (-23.419081106940197, 'proton pump')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=35000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35938)\n",
      "(10694, 35938)\n",
      "(203167, 35939)\n",
      "(10694, 35939)\n",
      "TRAIN: MSE: 3.105394, RMSE: 1.176030, R^2: 0.710401\n",
      "TEST: MSE: 4.692874, RMSE: 1.302546, R^2: 0.568646\n",
      "[(59.730961344474075, 'daili panic attack'), (48.538751550862216, 'mood swing headach'), (46.24017460938433, 'immedi side'), (35.51698898133801, 'harsh side'), (35.07659789887596, 'not birth control'), (33.970600836526664, 'look forward see'), (33.27902699044534, 'st john wort'), (31.896736248411, 'provera shot'), (30.499221359547448, 'suffer cystic'), (30.453169675651377, 'scari side')]\n",
      "[(-29.229510573482987, 'not birth'), (-29.631506900612035, 'forward see'), (-29.998955811143603, 'harsh side effect'), (-30.44957565869504, 'primari care physician'), (-31.34994799960479, 'scari side effect'), (-32.746844496191606, 'suffer cystic acn'), (-39.01045270502171, 'st john'), (-46.74250271874145, 'swing headach'), (-51.651091744837, 'immedi side effect'), (-60.99638633723775, 'daili panic')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=40000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 40000)\n",
      "(10694, 40000)\n",
      "(203167, 40938)\n",
      "(10694, 40938)\n",
      "(203167, 40939)\n",
      "(10694, 40939)\n",
      "TRAIN: MSE: 2.899742, RMSE: 1.156458, R^2: 0.729580\n",
      "TEST: MSE: 4.633232, RMSE: 1.300373, R^2: 0.574128\n",
      "[(18.608782206005404, 'dysphor disord'), (17.531409684006032, 'prostat hyperplasia'), (16.326846743446783, 'bleed complet'), (15.571391645294241, 'ice cube'), (15.55549046350285, 'revolv'), (14.621479795675876, 'folic'), (14.168325356699894, 'natur throid'), (13.175180363391133, 'vaginosi'), (12.895155531256723, 'magnesia'), (12.627145527905727, 'like clock')]\n",
      "[(-13.767351156417945, 'ideat'), (-14.152557788903078, 'say wait'), (-14.770893848138249, 'proton pump'), (-15.129808788079242, 'bacteri vaginosi'), (-15.197449994663835, 'clock work'), (-15.641978359534864, 'amox clav'), (-15.953535426424205, 'blue shield'), (-17.892197718934234, 'connect dot'), (-17.93281111872714, 'cube'), (-20.749932670276053, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=40000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 40000)\n",
      "(10694, 40000)\n",
      "(203167, 40938)\n",
      "(10694, 40938)\n",
      "(203167, 40939)\n",
      "(10694, 40939)\n",
      "TRAIN: MSE: 2.903336, RMSE: 1.155376, R^2: 0.729245\n",
      "TEST: MSE: 4.659386, RMSE: 1.299634, R^2: 0.571724\n",
      "[(54.163555717279664, 'daili panic attack'), (43.86841054893954, 'mood swing headach'), (42.28085527185465, 'strang side'), (40.76252993963636, 'not birth control'), (38.29395168959064, 'immedi side'), (37.7546997703493, 'harsh side'), (34.524884196674975, 'syndrom constip'), (33.69061214786757, 'viral load went'), (32.51680515750407, 'provera year'), (32.363779405483264, 'weight loss gain')]\n",
      "[(-30.957143655844916, 'pack per day'), (-31.373502993717292, 'primari care physician'), (-32.80823091960628, 'harsh side effect'), (-34.14921466486682, 'bowel syndrom constip'), (-34.261897664384925, 'load went'), (-34.54151027020334, 'not birth'), (-42.857703592647134, 'strang side effect'), (-43.342021014432625, 'swing headach'), (-44.997237034153684, 'immedi side effect'), (-56.43853672417833, 'daili panic')]\n"
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "for numFeatures in [20000, 25000, 30000, 35000, 40000]:\n",
    "    for max_ngram in [2, 3]: \n",
    "        min_ngram = 1\n",
    "\n",
    "        print(\"\\nRunning ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "        train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "        print(train_data_features.shape)\n",
    "        print(test_data_features.shape)\n",
    "\n",
    "        train_features = hstack((train_data_features,train_onehotlabels))\n",
    "        test_features = hstack((test_data_features,test_onehotlabels))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "        test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        model = getLinearRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        #for c in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        #    getRidgeRegressionResults(c, train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "        CoefNames.sort(reverse=True)\n",
    "        print(CoefNames[:10])\n",
    "        print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=45000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 45000)\n",
      "(10694, 45000)\n",
      "(203167, 45938)\n",
      "(10694, 45938)\n",
      "(203167, 45939)\n",
      "(10694, 45939)\n",
      "TRAIN: MSE: 2.706859, RMSE: 1.135828, R^2: 0.747567\n",
      "TEST: MSE: 4.622013, RMSE: 1.295699, R^2: 0.575159\n",
      "[(20.007228278080127, 'lo ovral'), (19.33342615906267, 'ice cube'), (18.160461697092586, 'esteem'), (18.0167069172588, 'folic'), (17.58641195356672, 'marrow'), (17.15886449831159, 'actin'), (16.20456691834221, 'bleed complet'), (16.092832401837764, 'natur throid'), (15.231300868639957, 'prostat hyperplasia'), (15.193268134905017, 'cross blue')]\n",
      "[(-16.39501350754571, 'bone marrow'), (-16.573572763230754, 'drug immedi'), (-17.376206060765405, 'ovral'), (-17.630729531436955, 'proton pump'), (-18.593265831667125, 'connect dot'), (-18.79022352831737, 'actin keratosi'), (-18.939490067624817, 'benign prostat'), (-18.94593100555609, 'self esteem'), (-21.59370953685239, 'cube'), (-31.614439191961708, 'blue shield')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=45000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 45000)\n",
      "(10694, 45000)\n",
      "(203167, 45938)\n",
      "(10694, 45938)\n",
      "(203167, 45939)\n",
      "(10694, 45939)\n",
      "TRAIN: MSE: 2.699339, RMSE: 1.133822, R^2: 0.748269\n",
      "TEST: MSE: 4.680957, RMSE: 1.300227, R^2: 0.569741\n",
      "[(51.54203297857367, 'daili panic attack'), (44.13258350865652, 'mood swing headach'), (43.47117024899121, 'strang side'), (42.691037220798684, 'harsh side'), (39.5183175873835, 'pack per'), (38.20531423276165, 'not birth control'), (36.66833575185663, 'immedi side'), (35.878580752304906, 'pregnant birth control'), (35.42772425082213, 'viral load went'), (35.415380618010985, 'back birth')]\n",
      "[(-33.041137769443914, 'not birth'), (-34.12998117479793, 'bowel syndrom constip'), (-35.48899109835353, 'load went'), (-37.8591770337014, 'harsh side effect'), (-39.85526937962656, 'back birth control'), (-42.22563582997808, 'pack per day'), (-43.34308480178702, 'immedi side effect'), (-43.579323144380105, 'swing headach'), (-44.33844501554893, 'strang side effect'), (-53.52705370359279, 'daili panic')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=50000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 50000)\n",
      "(10694, 50000)\n",
      "(203167, 50938)\n",
      "(10694, 50938)\n",
      "(203167, 50939)\n",
      "(10694, 50939)\n",
      "TRAIN: MSE: 2.515409, RMSE: 1.114284, R^2: 0.765421\n",
      "TEST: MSE: 4.684884, RMSE: 1.295975, R^2: 0.569380\n",
      "[(49.76645866952575, 'mgmt'), (35.50868176380122, 'supraventricular tachycardia'), (26.2024619907506, 'marrow'), (21.550499308874176, 'steven'), (21.418112961136885, 'esteem'), (21.179065773098873, 'magnesia'), (20.723026053829898, 'lo ovral'), (20.456821636035237, 'ice cube'), (20.247739040162788, 'pox'), (20.166236696000194, 'natur throid')]\n",
      "[(-20.8005869910589, 'milk magnesia'), (-21.615230642927585, 'chicken pox'), (-22.294607617680647, 'proton pump'), (-22.708528966768082, 'self esteem'), (-23.034738821405423, 'cube'), (-24.926925910036157, 'bone marrow'), (-28.643097444517924, 'supraventricular'), (-31.62819203300161, 'blue shield'), (-34.29048563306306, 'steven johnson'), (-53.247715680912066, 'pain mgmt')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=50000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 50000)\n",
      "(10694, 50000)\n",
      "(203167, 50938)\n",
      "(10694, 50938)\n",
      "(203167, 50939)\n",
      "(10694, 50939)\n",
      "TRAIN: MSE: 2.508596, RMSE: 1.112847, R^2: 0.766057\n",
      "TEST: MSE: 4.655799, RMSE: 1.297344, R^2: 0.572054\n",
      "[(53.00677625265808, 'side effect gas'), (52.34927273415198, 'fine ever sinc'), (51.23777878867853, 'strang side'), (50.722438453868854, 'harsh side'), (47.60429606316471, 'daili panic attack'), (46.649049937781946, 'mood swing headach'), (42.15295666516574, 'provera shot'), (40.258773473185066, 'pack per'), (40.05334639953641, 'not birth control'), (39.15199727452654, 'use pull method')]\n",
      "[(-38.23738549815835, 'find side effect'), (-38.39545925908365, 'depo provera shot'), (-41.79023035852429, 'pack per day'), (-42.76274532762372, 'immedi side effect'), (-45.988504351078376, 'swing headach'), (-46.30539593598452, 'harsh side effect'), (-47.07390867663815, 'fine ever'), (-49.22895322081575, 'effect gas'), (-49.67166971803011, 'daili panic'), (-52.02054986926654, 'strang side effect')]\n"
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "for numFeatures in [45000, 50000]:\n",
    "    for max_ngram in [2, 3]: \n",
    "        min_ngram = 1\n",
    "\n",
    "        print(\"\\nRunning ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "        train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "        print(train_data_features.shape)\n",
    "        print(test_data_features.shape)\n",
    "\n",
    "        train_features = hstack((train_data_features,train_onehotlabels))\n",
    "        test_features = hstack((test_data_features,test_onehotlabels))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "        test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        model = getLinearRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        #for c in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        #    getRidgeRegressionResults(c, train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "        CoefNames.sort(reverse=True)\n",
    "        print(CoefNames[:10])\n",
    "        print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF+one hot encoding day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=5000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 5000)\n",
      "(10694, 5000)\n",
      "(203167, 5969)\n",
      "(10694, 5969)\n",
      "(203167, 5970)\n",
      "(10694, 5970)\n",
      "TRAIN: MSE: 4.798531, RMSE: 1.315625, R^2: 0.552505\n",
      "TEST: MSE: 5.099312, RMSE: 1.336249, R^2: 0.531287\n",
      "[(7.648904199313731, 'esteem'), (5.901966738655186, 'rheumatoid'), (5.808010165308835, 'amaz'), (5.760173638080042, 'gotten pregnant'), (5.7211711333367825, 'godsend'), (5.637135089930472, 'bi polar'), (5.576794899090913, 'chang life'), (5.529374242229754, 'high recommend'), (5.442312270797019, 'love'), (5.277522828330202, 'miracl')]\n",
      "[(-6.858200524613088, 'no help'), (-6.956803446402874, 'no result'), (-7.195916373033634, 'no effect'), (-7.400600643528777, 'disappoint'), (-7.690013459752767, 'self esteem'), (-7.721023451841508, 'wors'), (-7.815691857829558, 'no relief'), (-8.412404211514893, 'not recommend'), (-9.053578824805015, 'no improv'), (-9.664408680702905, 'not worth')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=5000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 5000)\n",
      "(10694, 5000)\n",
      "(203167, 5969)\n",
      "(10694, 5969)\n",
      "(203167, 5970)\n",
      "(10694, 5970)\n",
      "TRAIN: MSE: 4.804817, RMSE: 1.315977, R^2: 0.551919\n",
      "TEST: MSE: 5.114869, RMSE: 1.338022, R^2: 0.529858\n",
      "[(18.256461789410334, 'gain acn'), (16.52802209597463, 'use birth control'), (14.289589394590468, 'stori short'), (13.526848272909554, 'side effect includ'), (11.769702936099186, 'wake middl night'), (10.987979169896912, 'terribl side'), (10.572339206889298, 'gain no'), (9.407115271757972, 'zero side'), (9.087229287833008, 'lot side effect'), (8.938704719874869, 'no weight gain')]\n",
      "[(-8.82694441351488, 'weight gain no'), (-9.058483300920214, 'no improv'), (-9.335172626351175, 'lot side'), (-10.003199008428759, 'not worth'), (-10.513179879535913, 'terribl side effect'), (-10.56016491230322, 'wake middl'), (-14.022102235864846, 'long stori short'), (-15.784395079736825, 'use birth'), (-16.453821406198617, 'effect includ'), (-17.83382212324424, 'weight gain acn')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=10000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 10000)\n",
      "(10694, 10000)\n",
      "(203167, 10969)\n",
      "(10694, 10969)\n",
      "(203167, 10970)\n",
      "(10694, 10970)\n",
      "TRAIN: MSE: 4.381633, RMSE: 1.284895, R^2: 0.591383\n",
      "TEST: MSE: 4.857794, RMSE: 1.318777, R^2: 0.553487\n",
      "[(13.019242790566185, 'sclerosi'), (9.197691883877699, 'suicid ideat'), (9.107407541450629, 'esteem'), (6.774716006673245, 'bi polar'), (6.501482164827333, 'spinal cord'), (6.238965914991872, 'rheumatoid'), (6.171087283094636, 'smear'), (6.073812271737416, 'no burn'), (6.045962510209794, 'chang life'), (5.9811884481238415, 'amaz')]\n",
      "[(-8.347357674556582, 'ale'), (-8.357267714555206, 'pleas care'), (-8.36767758671933, 'wors'), (-8.460979462425419, 'never recommend'), (-9.054604674597163, 'self esteem'), (-9.606645515453899, 'not recommend'), (-9.774961060501647, 'no improv'), (-10.334411601359724, 'not worth'), (-10.557938627690113, 'ideat'), (-10.585416491187209, 'multipl sclerosi')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=10000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 10000)\n",
      "(10694, 10000)\n",
      "(203167, 10969)\n",
      "(10694, 10969)\n",
      "(203167, 10970)\n",
      "(10694, 10970)\n",
      "TRAIN: MSE: 4.379367, RMSE: 1.284275, R^2: 0.591595\n",
      "TEST: MSE: 4.872354, RMSE: 1.318338, R^2: 0.552149\n",
      "[(24.7409252612948, 'weight gain gain'), (23.320736850743064, 'gain acn'), (19.976481260045723, 'side effect dizzi'), (19.162347829955976, 'put birth control'), (18.13873458576501, 'switch birth control'), (15.899393201517725, 'swing not'), (15.282036120492121, 'use birth control'), (14.602110501451927, 'signific side'), (14.362283221080904, 'sclerosi'), (13.77045563799415, 'stori short')]\n",
      "[(-14.824067946513116, 'get birth control'), (-14.892997685378802, 'use birth'), (-15.031447034334432, 'mood swing not'), (-16.00482277242554, 'effect includ'), (-16.57579822887531, 'hour unprotect'), (-18.732617698659336, 'put birth'), (-20.02685522581403, 'effect dizzi'), (-20.27595690527247, 'switch birth'), (-22.67169244076799, 'weight gain acn'), (-22.680107642319978, 'gain gain')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=15000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 15000)\n",
      "(10694, 15000)\n",
      "(203167, 15969)\n",
      "(10694, 15969)\n",
      "(203167, 15970)\n",
      "(10694, 15970)\n",
      "TRAIN: MSE: 4.062062, RMSE: 1.259892, R^2: 0.621186\n",
      "TEST: MSE: 4.776075, RMSE: 1.311899, R^2: 0.560998\n",
      "[(17.54861239887104, 'uric'), (16.04173956012219, 'magnesia'), (13.420095486112347, 'sclerosi'), (10.591150915965375, 'like clock'), (10.349385838814497, 'suicid ideat'), (10.27372528926941, 'esteem'), (9.092472674281504, 'go lie'), (8.457465018752519, 'folic'), (8.367055782986155, 'changer'), (8.272342223289566, 'bi polar')]\n",
      "[(-9.984789846680604, 'ale'), (-10.006451778958736, 'no improv'), (-10.221263890576417, 'not worth'), (-10.31377467933013, 'not impress'), (-10.560930252362194, 'clock work'), (-10.682332014252376, 'self esteem'), (-10.75214798209874, 'multipl sclerosi'), (-11.77648147358871, 'ideat'), (-14.603024581257127, 'milk magnesia'), (-16.540211071558346, 'uric acid')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=15000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 15000)\n",
      "(10694, 15000)\n",
      "(203167, 15969)\n",
      "(10694, 15969)\n",
      "(203167, 15970)\n",
      "(10694, 15970)\n",
      "TRAIN: MSE: 4.066851, RMSE: 1.260023, R^2: 0.620739\n",
      "TEST: MSE: 4.793084, RMSE: 1.312245, R^2: 0.559435\n",
      "[(43.397840000218146, 'mood swing headach'), (26.496036913902167, 'not birth control'), (25.334390053075765, 'gain acn'), (23.18035320749802, 'weight gain gain'), (21.755231788137035, 'side effect loss'), (20.656939325198614, 'provera shot'), (18.62423349896218, 'put birth control'), (17.17612998488506, 'signific side'), (17.045977944884037, 'swing not'), (16.872884532122573, 'magnesia')]\n",
      "[(-17.991236473655604, 'put birth'), (-18.227664806748784, 'effect includ'), (-18.575259300694555, 'depo provera shot'), (-19.415644009860696, 'switch birth'), (-20.111728597547355, 'effect loss'), (-20.6211642808489, 'get birth control'), (-21.141366455258115, 'gain gain'), (-22.917097785467348, 'not birth'), (-24.84123692749175, 'weight gain acn'), (-41.49918898654645, 'swing headach')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=20000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 20000)\n",
      "(10694, 20000)\n",
      "(203167, 20969)\n",
      "(10694, 20969)\n",
      "(203167, 20970)\n",
      "(10694, 20970)\n",
      "TRAIN: MSE: 3.798820, RMSE: 1.238539, R^2: 0.645735\n",
      "TEST: MSE: 4.732003, RMSE: 1.309661, R^2: 0.565049\n",
      "[(17.62910063982303, 'magnesia'), (17.032801271126484, 'natur throid'), (16.182605607298406, 'prostat hyperplasia'), (13.801456183279935, 'uric'), (13.159576168459951, 'sclerosi'), (12.083121229698348, 'john wort'), (12.066008073429536, 'suicid ideat'), (10.704057112757773, 'like clock'), (9.454522260875352, 'go lie'), (8.773954844708172, 'bi polar')]\n",
      "[(-10.245712766603473, 'not worth'), (-10.429576423208784, 'multipl sclerosi'), (-10.761309615701549, 'not impress'), (-11.354177831101413, 'clock work'), (-12.93154291951626, 'projectil vomit'), (-12.966255461918218, 'uric acid'), (-13.79002472322993, 'ideat'), (-14.412353323997626, 'throid'), (-16.370456619365818, 'milk magnesia'), (-17.319769257707797, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=20000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 20000)\n",
      "(10694, 20000)\n",
      "(203167, 20969)\n",
      "(10694, 20969)\n",
      "(203167, 20970)\n",
      "(10694, 20970)\n",
      "TRAIN: MSE: 3.798068, RMSE: 1.238507, R^2: 0.645805\n",
      "TEST: MSE: 4.710083, RMSE: 1.306288, R^2: 0.567064\n",
      "[(37.94927291732529, 'mood swing headach'), (27.468234284964666, 'not birth control'), (24.008541941399635, 'magnesia'), (23.431593751482136, 'tri lo sprintec'), (23.244915345053723, 'gain acn'), (22.92692069322135, 'put birth control'), (21.76936290376467, 'terribl side'), (20.981646315176356, 'weight gain gain'), (20.702158887745597, 'provera shot'), (19.648764882889363, 'swing not')]\n",
      "[(-19.26915136865, 'use birth'), (-19.699866544125488, 'mood swing not'), (-21.059440163353955, 'switch birth'), (-21.83928708114921, 'terribl side effect'), (-22.25686679848274, 'milk magnesia'), (-22.503638249976884, 'weight gain acn'), (-22.793499395658422, 'put birth'), (-23.076108634144312, 'not birth'), (-24.072564697393023, 'lo sprintec'), (-36.27138189436157, 'swing headach')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=25000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 25000)\n",
      "(10694, 25000)\n",
      "(203167, 25969)\n",
      "(10694, 25969)\n",
      "(203167, 25970)\n",
      "(10694, 25970)\n",
      "TRAIN: MSE: 3.551269, RMSE: 1.217753, R^2: 0.668820\n",
      "TEST: MSE: 4.709256, RMSE: 1.307319, R^2: 0.567140\n",
      "[(20.310301701666845, 'magnesia'), (19.289248484374777, 'natur throid'), (18.015288643503432, 'prostat hyperplasia'), (16.846811206895122, 'marrow'), (13.366953591037664, 'folic'), (13.22953482505294, 'tessalon perl'), (12.83823178987494, 'sclerosi'), (12.832776543186187, 'john wort'), (12.595303896748584, 'suicid ideat'), (10.73976958471627, 'pregnant second')]\n",
      "[(-11.210710080474389, 'not impress'), (-11.262421087339785, 'ale'), (-11.523437457490019, 'clock work'), (-11.905900967451295, 'perl'), (-13.957315925215578, 'projectil vomit'), (-14.668883173259292, 'ideat'), (-16.376945231117254, 'throid'), (-16.41617645648406, 'bone marrow'), (-18.594662642520422, 'benign prostat'), (-20.2492130703305, 'milk magnesia')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=25000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 25000)\n",
      "(10694, 25000)\n",
      "(203167, 25969)\n",
      "(10694, 25969)\n",
      "(203167, 25970)\n",
      "(10694, 25970)\n",
      "TRAIN: MSE: 3.547354, RMSE: 1.217117, R^2: 0.669186\n",
      "TEST: MSE: 4.700435, RMSE: 1.306438, R^2: 0.567951\n",
      "[(40.749085181434964, 'immedi side'), (40.175700404405205, 'mood swing headach'), (33.01251159272713, 'blood pressur year'), (29.83886637839386, 'not birth control'), (29.43399858400858, 'provera shot'), (28.40895564253868, 'care physician'), (27.434049771688745, 'magnesia'), (26.620061873299534, 'put birth control'), (26.333437750436556, 'scari side'), (25.898436196018118, 'terribl side')]\n",
      "[(-25.090299538875424, 'not birth'), (-25.924384064487214, 'put birth'), (-26.193718109659027, 'terribl side effect'), (-26.358476885628264, 'milk magnesia'), (-26.5272874469663, 'depo provera shot'), (-26.899052007235156, 'scari side effect'), (-30.608401646866188, 'primari care physician'), (-32.6161327592171, 'pressur year'), (-38.1554800735502, 'swing headach'), (-44.88039016499242, 'immedi side effect')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=30000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 30000)\n",
      "(10694, 30000)\n",
      "(203167, 30969)\n",
      "(10694, 30969)\n",
      "(203167, 30970)\n",
      "(10694, 30970)\n",
      "TRAIN: MSE: 3.320391, RMSE: 1.196793, R^2: 0.690351\n",
      "TEST: MSE: 4.683625, RMSE: 1.304529, R^2: 0.569496\n",
      "[(18.198016723284933, 'dysphor disord'), (18.033011802753766, 'natur throid'), (17.951283687074213, 'prostat hyperplasia'), (14.698793249888356, 'magnesia'), (13.785644502858425, 'marrow'), (12.018730766726202, 'tessalon perl'), (11.951470847561557, 'suicid ideat'), (11.76590793594664, 'john wort'), (11.675002696401998, 'pregnant second'), (11.13171371408153, 'like clock')]\n",
      "[(-12.054400011701158, 'littlest'), (-12.190497086481301, 'clock work'), (-12.503397232260173, 'put depress'), (-12.612963504767876, 'premenstru dysphor'), (-13.165286426046793, 'bone marrow'), (-13.421324578714469, 'ideat'), (-14.08324119736962, 'projectil vomit'), (-14.68731495096642, 'milk magnesia'), (-15.490151149007877, 'throid'), (-19.34041630017542, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=30000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 30000)\n",
      "(10694, 30000)\n",
      "(203167, 30969)\n",
      "(10694, 30969)\n",
      "(203167, 30970)\n",
      "(10694, 30970)\n",
      "TRAIN: MSE: 3.324642, RMSE: 1.197043, R^2: 0.689955\n",
      "TEST: MSE: 4.716191, RMSE: 1.305921, R^2: 0.566503\n",
      "[(41.86482653755547, 'immedi side'), (41.19485808755926, 'mood swing headach'), (33.206237429790384, 'not birth control'), (32.52997545289242, 'look forward see'), (32.26987657005519, 'harsh side'), (32.233111434466956, 'st john wort'), (31.514390567149427, 'blood pressur year'), (31.14035488135694, 'provera shot'), (29.163242342300514, 'care physician'), (28.407262556772213, 'strang side')]\n",
      "[(-27.4293045377024, 'depo provera shot'), (-28.154239584571812, 'not birth'), (-28.350083454605333, 'terribl side effect'), (-28.458872707550846, 'strang side effect'), (-29.065468885934365, 'forward see'), (-30.274831860073995, 'primari care physician'), (-31.074911555129496, 'pressur year'), (-38.978269099488465, 'st john'), (-39.8317813076991, 'swing headach'), (-46.006490321255214, 'immedi side effect')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=35000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35969)\n",
      "(10694, 35969)\n",
      "(203167, 35970)\n",
      "(10694, 35970)\n",
      "TRAIN: MSE: 3.104866, RMSE: 1.176297, R^2: 0.710450\n",
      "TEST: MSE: 4.650286, RMSE: 1.302979, R^2: 0.572561\n",
      "[(19.62062287555091, 'pump inhibitor'), (17.90442612352818, 'dysphor disord'), (17.643661766098464, 'magnesia'), (16.989668966423675, 'prostat hyperplasia'), (15.451904507769855, 'ice cube'), (14.550855983294545, 'natur throid'), (14.154418354005688, 'bleed complet'), (14.131015910515218, 'folic'), (13.375610084140847, 'tri nessa'), (13.073914679533738, 'marrow')]\n",
      "[(-12.516159317528604, 'throid'), (-12.591216440819554, 'put depress'), (-13.526346999592386, 'clock work'), (-13.925479698356117, 'cyclin'), (-14.624079121833567, 'littlest'), (-15.0077095141118, 'projectil vomit'), (-17.036158252626695, 'cube'), (-17.82385804075756, 'milk magnesia'), (-19.212439609326317, 'benign prostat'), (-24.273231952786958, 'proton pump')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=35000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35969)\n",
      "(10694, 35969)\n",
      "(203167, 35970)\n",
      "(10694, 35970)\n",
      "TRAIN: MSE: 3.104214, RMSE: 1.175891, R^2: 0.710511\n",
      "TEST: MSE: 4.688855, RMSE: 1.302344, R^2: 0.569015\n",
      "[(60.94391149038342, 'daili panic attack'), (49.20062886891979, 'mood swing headach'), (45.90662247504817, 'immedi side'), (36.12951466401879, 'harsh side'), (34.70720933033496, 'not birth control'), (34.376128078001976, 'look forward see'), (33.031970051584736, 'st john wort'), (31.5328462298306, 'provera shot'), (30.848094010237016, 'scari side'), (30.380933373592633, 'care physician')]\n",
      "[(-29.509004195163286, 'pressur year'), (-30.067909429438462, 'forward see'), (-30.544817825452373, 'harsh side effect'), (-30.702641978425937, 'primari care physician'), (-31.7463320431217, 'scari side effect'), (-32.54637752871826, 'suffer cystic acn'), (-38.891611922454274, 'st john'), (-47.38691093858431, 'swing headach'), (-51.32840241131427, 'immedi side effect'), (-62.291507647277776, 'daili panic')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=40000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 40000)\n",
      "(10694, 40000)\n",
      "(203167, 40969)\n",
      "(10694, 40969)\n",
      "(203167, 40970)\n",
      "(10694, 40970)\n",
      "TRAIN: MSE: 2.898725, RMSE: 1.156343, R^2: 0.729675\n",
      "TEST: MSE: 4.629966, RMSE: 1.300174, R^2: 0.574428\n",
      "[(18.649968440308896, 'dysphor disord'), (17.519131680379996, 'prostat hyperplasia'), (16.25600672158538, 'bleed complet'), (15.69372073134685, 'revolv'), (15.423458338326176, 'ice cube'), (14.702619292556655, 'folic'), (14.695724440236052, 'natur throid'), (12.956426617492067, 'magnesia'), (12.879397064276453, 'vaginosi'), (12.503721857742862, 'like clock')]\n",
      "[(-13.848611193922059, 'ideat'), (-14.092122996038588, 'say wait'), (-14.89552046704131, 'bacteri vaginosi'), (-15.001629073853605, 'proton pump'), (-15.072774122369962, 'clock work'), (-15.703935414153193, 'amox clav'), (-15.822774555456009, 'blue shield'), (-17.81835881481724, 'connect dot'), (-17.88561932367956, 'cube'), (-20.8897174139816, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=40000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 40000)\n",
      "(10694, 40000)\n",
      "(203167, 40969)\n",
      "(10694, 40969)\n",
      "(203167, 40970)\n",
      "(10694, 40970)\n",
      "TRAIN: MSE: 2.902327, RMSE: 1.155278, R^2: 0.729339\n",
      "TEST: MSE: 4.655947, RMSE: 1.299559, R^2: 0.572040\n",
      "[(54.60601084798474, 'daili panic attack'), (44.59588771592958, 'mood swing headach'), (42.24371656865865, 'strang side'), (40.103260746563095, 'not birth control'), (38.05136383806284, 'immedi side'), (37.88435998647265, 'harsh side'), (34.66609256146323, 'syndrom constip'), (33.25757867629031, 'viral load went'), (32.480071723821865, 'provera year'), (32.37068353565381, 'weight loss gain')]\n",
      "[(-31.25013859433733, 'pack per day'), (-31.51313136903773, 'primari care physician'), (-32.877662954215474, 'harsh side effect'), (-33.78981149129496, 'load went'), (-33.87273632150201, 'not birth'), (-34.36742523321801, 'bowel syndrom constip'), (-42.8241089637806, 'strang side effect'), (-44.066846643095104, 'swing headach'), (-44.74625581226195, 'immedi side effect'), (-56.96071351889783, 'daili panic')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=45000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 45000)\n",
      "(10694, 45000)\n",
      "(203167, 45969)\n",
      "(10694, 45969)\n",
      "(203167, 45970)\n",
      "(10694, 45970)\n",
      "TRAIN: MSE: 2.705930, RMSE: 1.135762, R^2: 0.747654\n",
      "TEST: MSE: 4.618981, RMSE: 1.295400, R^2: 0.575438\n",
      "[(20.200345198430078, 'lo ovral'), (18.908262438104888, 'ice cube'), (18.394583394058266, 'folic'), (18.23533694084646, 'esteem'), (18.186728512150935, 'marrow'), (17.67344075245512, 'actin'), (16.732639905897077, 'natur throid'), (16.167436416381108, 'bleed complet'), (15.453327185836255, 'cross blue'), (15.270329137223714, 'rite')]\n",
      "[(-16.536071112603686, 'drug immedi'), (-17.035043495421675, 'bone marrow'), (-17.57736173492728, 'ovral'), (-18.133289332254613, 'proton pump'), (-18.51024335118071, 'connect dot'), (-18.85268338673376, 'benign prostat'), (-19.041057068901136, 'self esteem'), (-19.31181926922658, 'actin keratosi'), (-21.27290004216791, 'cube'), (-31.826372180342, 'blue shield')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=45000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 45000)\n",
      "(10694, 45000)\n",
      "(203167, 45969)\n",
      "(10694, 45969)\n",
      "(203167, 45970)\n",
      "(10694, 45970)\n",
      "TRAIN: MSE: 2.698308, RMSE: 1.133721, R^2: 0.748365\n",
      "TEST: MSE: 4.676308, RMSE: 1.299999, R^2: 0.570169\n",
      "[(52.13686653061193, 'daili panic attack'), (44.79128536620617, 'mood swing headach'), (43.209083422591554, 'strang side'), (42.903489263990345, 'harsh side'), (39.67205843760648, 'pack per'), (37.77618269519981, 'not birth control'), (36.33141517843701, 'immedi side'), (35.666865748446185, 'pregnant birth control'), (35.34825036299412, 'back birth'), (34.9932735218334, 'syndrom constip')]\n",
      "[(-32.583786533150494, 'not birth'), (-34.32311072363461, 'bowel syndrom constip'), (-34.77362819256375, 'load went'), (-38.0104331066585, 'harsh side effect'), (-39.7948840385768, 'back birth control'), (-42.42835577351331, 'pack per day'), (-43.01216898740002, 'immedi side effect'), (-44.100226475055734, 'strang side effect'), (-44.235918994459595, 'swing headach'), (-54.20417026094063, 'daili panic')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=50000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 50000)\n",
      "(10694, 50000)\n",
      "(203167, 50969)\n",
      "(10694, 50969)\n",
      "(203167, 50970)\n",
      "(10694, 50970)\n",
      "TRAIN: MSE: 2.514606, RMSE: 1.114190, R^2: 0.765496\n",
      "TEST: MSE: 4.680844, RMSE: 1.295543, R^2: 0.569752\n",
      "[(50.8198480559524, 'mgmt'), (36.063300509026355, 'supraventricular tachycardia'), (26.785222656142867, 'marrow'), (21.68730971777459, 'esteem'), (21.645991275806928, 'magnesia'), (21.191001122700072, 'steven'), (20.777322238574577, 'lo ovral'), (20.616727044271958, 'natur throid'), (20.266114580325862, 'pox'), (19.97244676733365, 'folic')]\n",
      "[(-21.23280585197744, 'milk magnesia'), (-21.611533986988167, 'chicken pox'), (-22.614953357429442, 'cube'), (-22.6274482641938, 'proton pump'), (-22.98476892188253, 'self esteem'), (-25.55356419007911, 'bone marrow'), (-29.170432478002784, 'supraventricular'), (-31.353863374241474, 'blue shield'), (-33.99552366513969, 'steven johnson'), (-54.343004215072675, 'pain mgmt')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=50000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 50000)\n",
      "(10694, 50000)\n",
      "(203167, 50969)\n",
      "(10694, 50969)\n",
      "(203167, 50970)\n",
      "(10694, 50970)\n",
      "TRAIN: MSE: 2.507726, RMSE: 1.112731, R^2: 0.766138\n",
      "TEST: MSE: 4.652198, RMSE: 1.297226, R^2: 0.572385\n",
      "[(52.80427767448281, 'side effect gas'), (52.058547418622226, 'fine ever sinc'), (51.96491674443144, 'harsh side'), (50.677581864765884, 'strang side'), (48.751539675268745, 'daili panic attack'), (47.15126399252015, 'mood swing headach'), (41.789844289531, 'provera shot'), (40.298152570409044, 'pack per'), (39.98034458264834, 'not birth control'), (39.399617055845304, 'use pull method')]\n",
      "[(-38.057488898132114, 'depo provera shot'), (-38.47965171691324, 'find side effect'), (-41.841572833749545, 'pack per day'), (-42.74995759261557, 'immedi side effect'), (-46.47309482452495, 'swing headach'), (-46.786199969136156, 'fine ever'), (-47.491815070466416, 'harsh side effect'), (-48.951408960080606, 'effect gas'), (-50.909257178773494, 'daili panic'), (-51.46434089244218, 'strang side effect')]\n"
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "for numFeatures in [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000]:\n",
    "    for max_ngram in [2, 3]: \n",
    "        min_ngram = 1\n",
    "\n",
    "        print(\"\\nRunnpipelineing ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "        train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "        print(train_data_features.shape)\n",
    "        print(test_data_features.shape)\n",
    "\n",
    "        train_features = hstack((train_data_features,train_onehotlabels))\n",
    "        test_features = hstack((test_data_features,test_onehotlabels))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "        test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        model = getLinearRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        #for c in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        #    getRidgeRegressionResults(c, train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "        CoefNames.sort(reverse=True)\n",
    "        print(CoefNames[:10])\n",
    "        print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=5000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 5000)\n",
      "(10694, 5000)\n",
      "(203167, 5969)\n",
      "(10694, 5969)\n",
      "(203167, 5970)\n",
      "(10694, 5970)\n"
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "#for numFeatures in [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000]:\n",
    "for numFeatures in [5000]:\n",
    "    for max_ngram in [2, 3]: \n",
    "        min_ngram = 1\n",
    "\n",
    "        print(\"\\nRunnpipelineing ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "        train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "        print(train_data_features.shape)\n",
    "        print(test_data_features.shape)\n",
    "\n",
    "        train_features = hstack((train_data_features,train_onehotlabels))\n",
    "        test_features = hstack((test_data_features,test_onehotlabels))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "        test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        model = getKernelRidgeRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        #for c in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        #    getRidgeRegressionResults(c, train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "        CoefNames.sort(reverse=True)\n",
    "        print(CoefNames[:10])\n",
    "        print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=500,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 500)\n",
      "(10694, 500)\n",
      "(203167, 1469)\n",
      "(10694, 1469)\n",
      "(203167, 1470)\n",
      "(10694, 1470)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10building tree 2 of 10building tree 3 of 10building tree 4 of 10\n",
      "\n",
      "\n",
      "\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of  10 | elapsed: 16.2min remaining: 16.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   7 out of  10 | elapsed: 16.4min remaining:  7.0min\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed: 22.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: MSE: 0.568944, RMSE: 0.670003, R^2: 0.946942\n",
      "TEST: MSE: 2.893627, RMSE: 1.069079, R^2: 0.734027\n"
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "#for numFeatures in [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000]:\n",
    "numFeatures = 500\n",
    "max_ngram = 2 \n",
    "min_ngram = 1\n",
    "\n",
    "print(\"\\nRunnpipelineing ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "print(train_data_features.shape)\n",
    "print(test_data_features.shape)\n",
    "\n",
    "train_features = hstack((train_data_features,train_onehotlabels))\n",
    "test_features = hstack((test_data_features,test_onehotlabels))\n",
    "\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "model = getRandomForestRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "# CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "# CoefNames.sort(reverse=True)\n",
    "# print(CoefNames[:10])\n",
    "# print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.019389610897413312, 'wors'), (0.01656369484349604, 'love'), (0.016437302846474967, 'worst'), (0.016061934535862334, 'year'), (0.015420555612333806, 'not'), (0.014256552077432556, 'work'), (0.011685724652846523, 'great'), (0.011602785057188005, 'horribl'), (0.009130537364206864, 'best'), (0.008904020922999096, 'stop')]\n",
      "[(0.00027854417929121554, 'occasion'), (0.00027561761362450497, 'doctor prescrib'), (0.00026836803097430277, 'feel better'), (0.00026745938968473874, 'implant'), (0.00025582510241682345, 'honest'), (0.00025181992064656503, 'twice day'), (0.00025131551188566835, 'went away'), (0.00022672938287608804, 'crave'), (0.00022491396187258322, 'huge'), (0.0002028322144858673, 'dri mouth')]\n"
     ]
    }
   ],
   "source": [
    "CoefNames = list(zip(model.feature_importances_, vc.get_feature_names()))\n",
    "CoefNames.sort(reverse=True)\n",
    "print(CoefNames[:10])\n",
    "print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vc.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=2000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 2000)\n",
      "(10694, 2000)\n",
      "(203167, 2969)\n",
      "(10694, 2969)\n",
      "(203167, 2970)\n",
      "(10694, 2970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:22:42] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 8.011926, RMSE: 1.541510, R^2: 0.252834\n",
      "TEST: MSE: 8.135903, RMSE: 1.547289, R^2: 0.252174\n"
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "#for numFeatures in [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000]:\n",
    "numFeatures = 2000\n",
    "max_ngram = 2 \n",
    "min_ngram = 1\n",
    "\n",
    "print(\"\\nRunnpipelineing ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "print(train_data_features.shape)\n",
    "print(test_data_features.shape)\n",
    "\n",
    "train_features = hstack((train_data_features,train_onehotlabels))\n",
    "test_features = hstack((test_data_features,test_onehotlabels))\n",
    "\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "model = getXGBoostRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "# CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "# CoefNames.sort(reverse=True)\n",
    "# print(CoefNames[:10])\n",
    "# print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=5000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 5000)\n",
      "(10694, 5000)\n",
      "(203167, 5969)\n",
      "(10694, 5969)\n",
      "(203167, 5970)\n",
      "(10694, 5970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:30:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 8.016570, RMSE: 1.541376, R^2: 0.252401\n",
      "TEST: MSE: 8.149468, RMSE: 1.547166, R^2: 0.250927\n",
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=10000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 10000)\n",
      "(10694, 10000)\n",
      "(203167, 10969)\n",
      "(10694, 10969)\n",
      "(203167, 10970)\n",
      "(10694, 10970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:32:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 8.018871, RMSE: 1.541691, R^2: 0.252187\n",
      "TEST: MSE: 8.161489, RMSE: 1.548347, R^2: 0.249822\n",
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=15000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 15000)\n",
      "(10694, 15000)\n",
      "(203167, 15969)\n",
      "(10694, 15969)\n",
      "(203167, 15970)\n",
      "(10694, 15970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:35:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 8.015161, RMSE: 1.541905, R^2: 0.252533\n",
      "TEST: MSE: 8.158932, RMSE: 1.548197, R^2: 0.250057\n",
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=20000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 20000)\n",
      "(10694, 20000)\n",
      "(203167, 20969)\n",
      "(10694, 20969)\n",
      "(203167, 20970)\n",
      "(10694, 20970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:38:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 8.019862, RMSE: 1.542125, R^2: 0.252094\n",
      "TEST: MSE: 8.151239, RMSE: 1.548164, R^2: 0.250764\n",
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=25000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 25000)\n",
      "(10694, 25000)\n",
      "(203167, 25969)\n",
      "(10694, 25969)\n",
      "(203167, 25970)\n",
      "(10694, 25970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 8.038325, RMSE: 1.542869, R^2: 0.250372\n",
      "TEST: MSE: 8.171974, RMSE: 1.548851, R^2: 0.248858\n",
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=30000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 30000)\n",
      "(10694, 30000)\n",
      "(203167, 30969)\n",
      "(10694, 30969)\n",
      "(203167, 30970)\n",
      "(10694, 30970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:44:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 8.013873, RMSE: 1.541795, R^2: 0.252653\n",
      "TEST: MSE: 8.147023, RMSE: 1.547758, R^2: 0.251152\n",
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=35000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35969)\n",
      "(10694, 35969)\n",
      "(203167, 35970)\n",
      "(10694, 35970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 8.020133, RMSE: 1.541757, R^2: 0.252069\n",
      "TEST: MSE: 8.160714, RMSE: 1.548115, R^2: 0.249893\n",
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=40000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 40000)\n",
      "(10694, 40000)\n",
      "(203167, 40969)\n",
      "(10694, 40969)\n",
      "(203167, 40970)\n",
      "(10694, 40970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:50:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-68479a7aeef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetXGBoostRegressionResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# CoefNames = list(zip(model.coef_, vc.get_feature_names()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-b7bd289a1869>\u001b[0m in \u001b[0;36mgetXGBoostRegressionResults\u001b[0;34m(train_x, train_y, test_x, test_y)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgbr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "for numFeatures in [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000]:\n",
    "    max_ngram = 2 \n",
    "    min_ngram = 1\n",
    "\n",
    "    print(\"\\nRunnpipelineing ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "    train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "    print(train_data_features.shape)\n",
    "    print(test_data_features.shape)\n",
    "\n",
    "    train_features = hstack((train_data_features,train_onehotlabels))\n",
    "    test_features = hstack((test_data_features,test_onehotlabels))\n",
    "\n",
    "    print(train_features.shape)\n",
    "    print(test_features.shape)\n",
    "\n",
    "    train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "    test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "\n",
    "    print(train_features.shape)\n",
    "    print(test_features.shape)\n",
    "\n",
    "    model = getXGBoostRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "    # CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "    # CoefNames.sort(reverse=True)\n",
    "    # print(CoefNames[:10])\n",
    "    # print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=5000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 5000)\n",
      "(10694, 5000)\n",
      "(203167, 5969)\n",
      "(10694, 5969)\n",
      "(203167, 5970)\n",
      "(10694, 5970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:54:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 7.288851, RMSE: 1.492533, R^2: 0.320266\n",
      "TEST: MSE: 7.403891, RMSE: 1.496920, R^2: 0.319458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:58:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 6.866210, RMSE: 1.464892, R^2: 0.359680\n",
      "TEST: MSE: 6.971095, RMSE: 1.468851, R^2: 0.359239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:03:18] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 6.564069, RMSE: 1.444482, R^2: 0.387857\n",
      "TEST: MSE: 6.671246, RMSE: 1.448726, R^2: 0.386800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:10:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 5.668437, RMSE: 1.382065, R^2: 0.471380\n",
      "TEST: MSE: 5.834782, RMSE: 1.391043, R^2: 0.463685\n",
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=10000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-714333ca0fe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nRunnpipelineing ngram(%d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmin_ngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_data_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTFIDFFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumFeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-6d6ab907e2c8>\u001b[0m in \u001b[0;36mgetTFIDFFeatures\u001b[0;34m(minNgram, maxNgram, df_train, df_test, num_features)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_data_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtest_data_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1650\u001b[0m         \"\"\"\n\u001b[1;32m   1651\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                                                        max_features)\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[0;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[1;32m    948\u001b[0m             raise ValueError(\"After pruning, no terms remain. Try a lower\"\n\u001b[1;32m    949\u001b[0m                              \" min_df or a higher max_df.\")\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoved_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sliceXslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sliceXarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index results in >2 dimensions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m_get_sliceXarray\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_sliceXarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_major_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_index_fancy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_arrayXint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_minor_index_fancy\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mres_indptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         csr_column_index1(k, idx, M, N, self.indptr, self.indices,\n\u001b[0;32m--> 749\u001b[0;31m                           col_offsets, res_indptr)\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;31m# pass 2: copy indices/data for selected idxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "for numFeatures in [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000]:\n",
    "    max_ngram = 2 \n",
    "    min_ngram = 1\n",
    "\n",
    "    print(\"\\nRunnpipelineing ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "    train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "    print(train_data_features.shape)\n",
    "    print(test_data_features.shape)\n",
    "\n",
    "    train_features = hstack((train_data_features,train_onehotlabels))\n",
    "    test_features = hstack((test_data_features,test_onehotlabels))\n",
    "\n",
    "    print(train_features.shape)\n",
    "    print(test_features.shape)\n",
    "\n",
    "    train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "    test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "\n",
    "    print(train_features.shape)\n",
    "    print(test_features.shape)\n",
    "\n",
    "    for n_est in [100,150,200,500]:\n",
    "        model = getXGBoostRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"], n_est)\n",
    "\n",
    "    # CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "    # CoefNames.sort(reverse=True)\n",
    "    # print(CoefNames[:10])\n",
    "    # print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=5000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 5000)\n",
      "(10694, 5000)\n",
      "(203167, 5969)\n",
      "(10694, 5969)\n",
      "(203167, 5970)\n",
      "(10694, 5970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:29:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 7.288851, RMSE: 1.492533, R^2: 0.320266\n",
      "TEST: MSE: 7.403891, RMSE: 1.496920, R^2: 0.319458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 6.866210, RMSE: 1.464892, R^2: 0.359680\n",
      "TEST: MSE: 6.971095, RMSE: 1.468851, R^2: 0.359239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:38:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 6.564069, RMSE: 1.444482, R^2: 0.387857\n",
      "TEST: MSE: 6.671246, RMSE: 1.448726, R^2: 0.386800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:46:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 5.668437, RMSE: 1.382065, R^2: 0.471380\n",
      "TEST: MSE: 5.834782, RMSE: 1.391043, R^2: 0.463685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:02:04] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 5.291862, RMSE: 1.354844, R^2: 0.506499\n",
      "TEST: MSE: 5.531615, RMSE: 1.368487, R^2: 0.491552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:29:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 5.032234, RMSE: 1.336099, R^2: 0.530711\n",
      "TEST: MSE: 5.339009, RMSE: 1.353865, R^2: 0.509255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 4.656900, RMSE: 1.308679, R^2: 0.565713\n",
      "TEST: MSE: 5.076472, RMSE: 1.334271, R^2: 0.533387\n",
      "\n",
      "Runnpipelineing ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=10000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 10000)\n",
      "(10694, 10000)\n",
      "(203167, 10969)\n",
      "(10694, 10969)\n",
      "(203167, 10970)\n",
      "(10694, 10970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:46:12] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 7.283223, RMSE: 1.492719, R^2: 0.320791\n",
      "TEST: MSE: 7.404310, RMSE: 1.497977, R^2: 0.319419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:48:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 6.854774, RMSE: 1.464515, R^2: 0.360747\n",
      "TEST: MSE: 6.967937, RMSE: 1.469655, R^2: 0.359530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:52:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 6.559391, RMSE: 1.444916, R^2: 0.388293\n",
      "TEST: MSE: 6.672158, RMSE: 1.449961, R^2: 0.386716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:58:02] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6532de406825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn_est\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m750\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetXGBoostRegressionResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# CoefNames = list(zip(model.coef_, vc.get_feature_names()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-5c55a0635d29>\u001b[0m in \u001b[0;36mgetXGBoostRegressionResults\u001b[0;34m(train_x, train_y, test_x, test_y, n_est)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgbr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "for numFeatures in [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000]:\n",
    "    max_ngram = 2 \n",
    "    min_ngram = 1\n",
    "\n",
    "    print(\"\\nRunnpipelineing ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "    train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "    print(train_data_features.shape)\n",
    "    print(test_data_features.shape)\n",
    "\n",
    "    train_features = hstack((train_data_features,train_onehotlabels))\n",
    "    test_features = hstack((test_data_features,test_onehotlabels))\n",
    "\n",
    "    print(train_features.shape)\n",
    "    print(test_features.shape)\n",
    "\n",
    "    train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "    test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "\n",
    "    print(train_features.shape)\n",
    "    print(test_features.shape)\n",
    "\n",
    "    for n_est in [100,150,200,500,750,1000,1500]:\n",
    "        model = getXGBoostRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"], n_est)\n",
    "\n",
    "    # CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "    # CoefNames.sort(reverse=True)\n",
    "    # print(CoefNames[:10])\n",
    "    # print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Runnpipelineing ngram(1, 2), numFeatures:5000\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=5000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 5000)\n",
      "(10694, 5000)\n",
      "(203167, 5969)\n",
      "(10694, 5969)\n",
      "(203167, 5970)\n",
      "(10694, 5970)\n",
      "\n",
      "# est:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:07:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 7.288851, RMSE: 1.492533, R^2: 0.320266\n",
      "TEST: MSE: 7.403891, RMSE: 1.496920, R^2: 0.319458\n",
      "\n",
      "# est:150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 6.866210, RMSE: 1.464892, R^2: 0.359680\n",
      "TEST: MSE: 6.971095, RMSE: 1.468851, R^2: 0.359239\n",
      "\n",
      "# est:200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:13:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 6.564069, RMSE: 1.444482, R^2: 0.387857\n",
      "TEST: MSE: 6.671246, RMSE: 1.448726, R^2: 0.386800\n",
      "\n",
      "# est:500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:18:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 5.668437, RMSE: 1.382065, R^2: 0.471380\n",
      "TEST: MSE: 5.834782, RMSE: 1.391043, R^2: 0.463685\n",
      "\n",
      "# est:750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:29:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 5.291862, RMSE: 1.354844, R^2: 0.506499\n",
      "TEST: MSE: 5.531615, RMSE: 1.368487, R^2: 0.491552\n",
      "\n",
      "# est:1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:46:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 5.032234, RMSE: 1.336099, R^2: 0.530711\n",
      "TEST: MSE: 5.339009, RMSE: 1.353865, R^2: 0.509255\n",
      "\n",
      "# est:1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:18] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 4.656900, RMSE: 1.308679, R^2: 0.565713\n",
      "TEST: MSE: 5.076472, RMSE: 1.334271, R^2: 0.533387\n",
      "\n",
      "# est:2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:43:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 4.382849, RMSE: 1.288310, R^2: 0.591270\n",
      "TEST: MSE: 4.898440, RMSE: 1.321137, R^2: 0.549751\n",
      "\n",
      "# est:2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:29:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 4.156835, RMSE: 1.271034, R^2: 0.612347\n",
      "TEST: MSE: 4.748474, RMSE: 1.310104, R^2: 0.563535\n",
      "\n",
      "# est:3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:26:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 3.968869, RMSE: 1.256482, R^2: 0.629876\n",
      "TEST: MSE: 4.624279, RMSE: 1.301048, R^2: 0.574951\n",
      "\n",
      "Runnpipelineing ngram(1, 2), numFeatures:10000\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=10000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 10000)\n",
      "(10694, 10000)\n",
      "(203167, 10969)\n",
      "(10694, 10969)\n",
      "(203167, 10970)\n",
      "(10694, 10970)\n",
      "\n",
      "# est:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:33:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 7.283223, RMSE: 1.492719, R^2: 0.320791\n",
      "TEST: MSE: 7.404310, RMSE: 1.497977, R^2: 0.319419\n",
      "\n",
      "# est:150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:36:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 6.854774, RMSE: 1.464515, R^2: 0.360747\n",
      "TEST: MSE: 6.967937, RMSE: 1.469655, R^2: 0.359530\n",
      "\n",
      "# est:200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:40:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 6.559391, RMSE: 1.444916, R^2: 0.388293\n",
      "TEST: MSE: 6.672158, RMSE: 1.449961, R^2: 0.386716\n",
      "\n",
      "# est:500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:45:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 5.655630, RMSE: 1.382165, R^2: 0.472575\n",
      "TEST: MSE: 5.827870, RMSE: 1.391705, R^2: 0.464321\n",
      "\n",
      "# est:750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:58:02] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 5.281271, RMSE: 1.355281, R^2: 0.507486\n",
      "TEST: MSE: 5.518505, RMSE: 1.368498, R^2: 0.492757\n",
      "\n",
      "# est:1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:16:54] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 5.015945, RMSE: 1.336387, R^2: 0.532230\n",
      "TEST: MSE: 5.314127, RMSE: 1.353622, R^2: 0.511542\n",
      "\n",
      "# est:1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:41:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 4.641163, RMSE: 1.308874, R^2: 0.567181\n",
      "TEST: MSE: 5.039041, RMSE: 1.332997, R^2: 0.536827\n",
      "\n",
      "# est:2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:19:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 4.362848, RMSE: 1.288004, R^2: 0.593135\n",
      "TEST: MSE: 4.850741, RMSE: 1.318837, R^2: 0.554135\n",
      "\n",
      "# est:2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:08:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 4.141332, RMSE: 1.270807, R^2: 0.613793\n",
      "TEST: MSE: 4.702692, RMSE: 1.307798, R^2: 0.567744\n",
      "\n",
      "# est:3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:10:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 3.948254, RMSE: 1.255477, R^2: 0.631799\n",
      "TEST: MSE: 4.578669, RMSE: 1.297964, R^2: 0.579143\n",
      "\n",
      "Runnpipelineing ngram(1, 2), numFeatures:15000\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=15000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 15000)\n",
      "(10694, 15000)\n",
      "(203167, 15969)\n",
      "(10694, 15969)\n",
      "(203167, 15970)\n",
      "(10694, 15970)\n",
      "\n",
      "# est:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:33:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 7.276794, RMSE: 1.492389, R^2: 0.321390\n",
      "TEST: MSE: 7.402198, RMSE: 1.497321, R^2: 0.319614\n",
      "\n",
      "# est:150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:36:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "TRAIN: MSE: 6.850821, RMSE: 1.464192, R^2: 0.361115\n",
      "TEST: MSE: 6.968685, RMSE: 1.468787, R^2: 0.359461\n",
      "\n",
      "# est:200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/usr/local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:41:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e0d910520966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn_est\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m750\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n# est:%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetXGBoostRegressionResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# CoefNames = list(zip(model.coef_, vc.get_feature_names()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-5c55a0635d29>\u001b[0m in \u001b[0;36mgetXGBoostRegressionResults\u001b[0;34m(train_x, train_y, test_x, test_y, n_est)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgbr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "for numFeatures in [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000]:\n",
    "    max_ngram = 2 \n",
    "    min_ngram = 1\n",
    "\n",
    "    print(\"\\nRunnpipelineing ngram(%d, %d), numFeatures:%d\" % (min_ngram, max_ngram, numFeatures))\n",
    "    train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "    print(train_data_features.shape)\n",
    "    print(test_data_features.shape)\n",
    "\n",
    "    train_features = hstack((train_data_features,train_onehotlabels))\n",
    "    test_features = hstack((test_data_features,test_onehotlabels))\n",
    "\n",
    "    print(train_features.shape)\n",
    "    print(test_features.shape)\n",
    "\n",
    "    train_features = hstack((train_features, np.array([df_train[\"usefulCount\"].to_numpy()]).T))\n",
    "    test_features = hstack((test_features, np.array([df_test[\"usefulCount\"].to_numpy()]).T))\n",
    "\n",
    "    print(train_features.shape)\n",
    "    print(test_features.shape)\n",
    "\n",
    "    for n_est in [100,150,200,500,750,1000,1500,2000,2500,3000]:\n",
    "        print(\"\\n# est:%d\" % (n_est))\n",
    "        model = getXGBoostRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"], n_est)\n",
    "\n",
    "    # CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "    # CoefNames.sort(reverse=True)\n",
    "    # print(CoefNames[:10])\n",
    "    # print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF+Normalized usefulCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized usefulCount\n",
    "normUsefulCount_train = [x/1291.0 for x in df_train[\"usefulCount\"].to_list()]\n",
    "normUsefulCount_test = [x/1291.0 for x in df_test[\"usefulCount\"].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=20000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 20000)\n",
      "(10694, 20000)\n",
      "(203167, 20938)\n",
      "(10694, 20938)\n",
      "(203167, 20939)\n",
      "(10694, 20939)\n",
      "TRAIN: MSE: 3.800086, RMSE: 1.238624, R^2: 0.645617\n",
      "TEST: MSE: 4.733347, RMSE: 1.309546, R^2: 0.564926\n",
      "[(24.184275483054506, 'magnesia'), (16.558894732673426, 'natur throid'), (14.739780963207277, 'prostat hyperplasia'), (13.631622708408273, 'sclerosi'), (12.948218108250433, 'uric'), (12.153448511831353, 'suicid ideat'), (11.902444601040743, 'john wort'), (11.079467556855375, 'like clock'), (9.417510408408038, 'go lie'), (8.898767641643232, 'bi polar')]\n",
      "[(-10.227938065416392, 'not worth'), (-10.775980391140275, 'not impress'), (-10.916510099479584, 'multipl sclerosi'), (-11.763277240230746, 'clock work'), (-12.022100997389579, 'uric acid'), (-13.287458764192982, 'projectil vomit'), (-13.938208510461616, 'ideat'), (-13.974029597246936, 'throid'), (-15.807601565491977, 'benign prostat'), (-22.95414325516874, 'milk magnesia')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=20000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 20000)\n",
      "(10694, 20000)\n",
      "(203167, 20938)\n",
      "(10694, 20938)\n",
      "(203167, 20939)\n",
      "(10694, 20939)\n",
      "TRAIN: MSE: 3.799387, RMSE: 1.238613, R^2: 0.645682\n",
      "TEST: MSE: 4.711911, RMSE: 1.306301, R^2: 0.566896\n",
      "[(35.6810958608729, 'mood swing headach'), (31.97083323227378, 'not birth control'), (27.184501478095964, 'magnesia'), (25.267141650134526, 'terribl side'), (23.592198071950598, 'tri lo sprintec'), (22.292113263509112, 'gain acn'), (21.452191576079027, 'put birth control'), (21.076862825912468, 'pressur medicin'), (20.79902541487024, 'provera shot'), (19.7120985044909, 'use birth control')]\n",
      "[(-19.12411749885072, 'mood swing not'), (-20.017923734674742, 'use birth'), (-21.324407956206898, 'put birth'), (-21.350495810970948, 'switch birth'), (-21.540187344851695, 'weight gain acn'), (-24.241695072867085, 'lo sprintec'), (-25.33697841458655, 'terribl side effect'), (-25.454463835867173, 'milk magnesia'), (-27.56559579247051, 'not birth'), (-34.02166549630219, 'swing headach')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=25000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 25000)\n",
      "(10694, 25000)\n",
      "(203167, 25938)\n",
      "(10694, 25938)\n",
      "(203167, 25939)\n",
      "(10694, 25939)\n",
      "TRAIN: MSE: 3.552571, RMSE: 1.217904, R^2: 0.668699\n",
      "TEST: MSE: 4.711468, RMSE: 1.307385, R^2: 0.566937\n",
      "[(25.26727942381194, 'magnesia'), (22.067086268861548, 'marrow'), (16.869770063416738, 'prostat hyperplasia'), (16.42131624851201, 'natur throid'), (13.39757005507329, 'sclerosi'), (13.296860107713735, 'john wort'), (12.936317971099141, 'folic'), (12.81476789754236, 'tessalon perl'), (12.437190976250205, 'suicid ideat'), (10.796976176816557, 'pregnant second')]\n",
      "[(-11.161146880237194, 'ale'), (-11.243621131900511, 'not impress'), (-11.551560658819373, 'perl'), (-12.02003980282564, 'clock work'), (-13.556852626817612, 'throid'), (-14.118672890527261, 'projectil vomit'), (-14.57639744436768, 'ideat'), (-17.33175942811867, 'benign prostat'), (-21.659909477255557, 'bone marrow'), (-25.215506190037587, 'milk magnesia')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=25000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 25000)\n",
      "(10694, 25000)\n",
      "(203167, 25938)\n",
      "(10694, 25938)\n",
      "(203167, 25939)\n",
      "(10694, 25939)\n",
      "TRAIN: MSE: 3.548485, RMSE: 1.217199, R^2: 0.669080\n",
      "TEST: MSE: 4.702681, RMSE: 1.306480, R^2: 0.567745\n",
      "[(40.88365352255169, 'blood pressur year'), (40.16696550643441, 'immedi side'), (37.09566843930058, 'mood swing headach'), (32.076322642549876, 'not birth control'), (30.35739259958001, 'magnesia'), (29.87244801803428, 'scari side'), (29.161297866775072, 'care physician'), (28.429340680956106, 'provera shot'), (27.64004063850616, 'terribl side'), (25.028191239767473, 'give side effect')]\n",
      "[(-25.482485843059216, 'depo provera shot'), (-26.816636868837303, 'st john'), (-27.312980665941506, 'not birth'), (-27.92315939817883, 'terribl side effect'), (-29.290152041072602, 'milk magnesia'), (-30.45430676780175, 'scari side effect'), (-31.372168586412094, 'primari care physician'), (-35.09738330059796, 'swing headach'), (-40.4393925167788, 'pressur year'), (-44.28209939385075, 'immedi side effect')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=30000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 30000)\n",
      "(10694, 30000)\n",
      "(203167, 30938)\n",
      "(10694, 30938)\n",
      "(203167, 30939)\n",
      "(10694, 30939)\n",
      "TRAIN: MSE: 3.321757, RMSE: 1.196931, R^2: 0.690224\n",
      "TEST: MSE: 4.686258, RMSE: 1.304502, R^2: 0.569254\n",
      "[(19.528732524666534, 'magnesia'), (19.337392899598406, 'marrow'), (17.698883872080902, 'dysphor disord'), (16.75995613218417, 'prostat hyperplasia'), (16.122471513514064, 'natur throid'), (12.080538317856355, 'john wort'), (11.995801601337, 'suicid ideat'), (11.742123549021228, 'pregnant second'), (11.615975946706156, 'like clock'), (11.581786762613229, 'tessalon perl')]\n",
      "[(-11.94367998678968, 'littlest'), (-12.291943657223838, 'premenstru dysphor'), (-12.646331023730644, 'put depress'), (-12.701422320084028, 'clock work'), (-13.520940142181129, 'ideat'), (-13.620198130649609, 'throid'), (-14.435295298803831, 'projectil vomit'), (-18.005590552684975, 'benign prostat'), (-18.713087097561356, 'bone marrow'), (-19.529129581646092, 'milk magnesia')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=30000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 30000)\n",
      "(10694, 30000)\n",
      "(203167, 30938)\n",
      "(10694, 30938)\n",
      "(203167, 30939)\n",
      "(10694, 30939)\n",
      "TRAIN: MSE: 3.325916, RMSE: 1.197152, R^2: 0.689836\n",
      "TEST: MSE: 4.719646, RMSE: 1.306043, R^2: 0.566185\n",
      "[(40.9480945999536, 'immedi side'), (38.36904062122725, 'mood swing headach'), (37.585234612095356, 'blood pressur year'), (36.37243448274943, 'st john wort'), (35.756746233829524, 'harsh side'), (34.94468624041985, 'not birth control'), (31.104207743958217, 'look forward see'), (30.447920613415572, 'provera shot'), (30.120776641902154, 'care physician'), (29.34274108993031, 'terribl side')]\n",
      "[(-27.61817895655638, 'forward see'), (-29.706159102283785, 'scari side effect'), (-29.881693965783825, 'terribl side effect'), (-29.89320094803253, 'not birth'), (-30.474653904287717, 'harsh side effect'), (-31.289727637732145, 'primari care physician'), (-37.02829835750503, 'swing headach'), (-37.078097212063064, 'pressur year'), (-42.71461623561751, 'st john'), (-45.077873816862535, 'immedi side effect')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=35000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35938)\n",
      "(10694, 35938)\n",
      "(203167, 35939)\n",
      "(10694, 35939)\n",
      "TRAIN: MSE: 3.106119, RMSE: 1.176413, R^2: 0.710334\n",
      "TEST: MSE: 4.652209, RMSE: 1.302970, R^2: 0.572384\n",
      "[(23.535978313844783, 'magnesia'), (19.542550874934374, 'pump inhibitor'), (17.861332290663004, 'dysphor disord'), (17.662257428658048, 'marrow'), (16.37874514681723, 'prostat hyperplasia'), (15.086883909113833, 'folic'), (14.246926857394012, 'bleed complet'), (14.117647699195482, 'ice cube'), (13.263917661089298, 'natur throid'), (12.865996580761, 'like clock')]\n",
      "[(-12.705603867357862, 'put depress'), (-13.915376898535579, 'cyclin'), (-14.127895731593712, 'clock work'), (-14.48790537889674, 'littlest'), (-15.470397535044686, 'projectil vomit'), (-15.689683951769691, 'cube'), (-16.421567779209646, 'bone marrow'), (-18.480899715243808, 'benign prostat'), (-23.73660077093638, 'milk magnesia'), (-24.197710204769862, 'proton pump')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=35000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 35000)\n",
      "(10694, 35000)\n",
      "(203167, 35938)\n",
      "(10694, 35938)\n",
      "(203167, 35939)\n",
      "(10694, 35939)\n",
      "TRAIN: MSE: 3.105365, RMSE: 1.175996, R^2: 0.710404\n",
      "TEST: MSE: 4.693049, RMSE: 1.302531, R^2: 0.568630\n",
      "[(62.990327927118926, 'daili panic attack'), (46.07839055778458, 'mood swing headach'), (44.608415008687615, 'immedi side'), (39.71407835772422, 'harsh side'), (37.47569326263522, 'st john wort'), (35.59895049036353, 'not birth control'), (35.00311937298792, 'blood pressur year'), (33.38156624378456, 'scari side'), (32.685915223261965, 'look forward see'), (31.26517374705114, 'care physician')]\n",
      "[(-29.75349529035687, 'not birth'), (-31.6153437976748, 'suffer cystic acn'), (-31.656471230685607, 'primari care physician'), (-34.16126887615706, 'pressur year'), (-34.19621422669509, 'harsh side effect'), (-34.284874422967086, 'scari side effect'), (-42.945501072957654, 'st john'), (-44.29308320373224, 'swing headach'), (-50.010533034994154, 'immedi side effect'), (-64.24217085530127, 'daili panic')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=40000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 40000)\n",
      "(10694, 40000)\n",
      "(203167, 40938)\n",
      "(10694, 40938)\n",
      "(203167, 40939)\n",
      "(10694, 40939)\n",
      "TRAIN: MSE: 2.899724, RMSE: 1.156447, R^2: 0.729581\n",
      "TEST: MSE: 4.632839, RMSE: 1.300299, R^2: 0.574164\n",
      "[(19.860723930246262, 'magnesia'), (18.271907463099424, 'dysphor disord'), (17.773561632659316, 'marrow'), (16.977912895061742, 'prostat hyperplasia'), (16.518005930302767, 'folic'), (16.329726951240154, 'bleed complet'), (14.423329245579998, 'revolv'), (14.340582705729515, 'natur throid'), (14.121054669618134, 'ice cube'), (12.883264172118796, 'esteem')]\n",
      "[(-14.199020636140407, 'bacteri vaginosi'), (-15.233339833251481, 'blue shield'), (-15.241050542419234, 'clock work'), (-15.369581869527009, 'amox clav'), (-16.51369788826823, 'cube'), (-16.644147839568138, 'bone marrow'), (-16.782712535963515, 'proton pump'), (-17.88319144086661, 'connect dot'), (-19.775987938541963, 'milk magnesia'), (-20.21774452592382, 'benign prostat')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=40000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 40000)\n",
      "(10694, 40000)\n",
      "(203167, 40938)\n",
      "(10694, 40938)\n",
      "(203167, 40939)\n",
      "(10694, 40939)\n",
      "TRAIN: MSE: 2.903310, RMSE: 1.155346, R^2: 0.729247\n",
      "TEST: MSE: 4.659866, RMSE: 1.299623, R^2: 0.571680\n",
      "[(56.50831837921948, 'daili panic attack'), (42.89356274290024, 'harsh side'), (42.28280652728259, 'mood swing headach'), (41.364939091700684, 'not birth control'), (40.69336498819212, 'strang side'), (37.72874563719054, 'immedi side'), (35.22215633185585, 'syndrom constip'), (32.538403470671966, 'scari side'), (32.43686331697162, 'viral load went'), (32.27739493639905, 'care physician')]\n",
      "[(-32.50458904188861, 'primari care physician'), (-33.03171881201325, 'load went'), (-34.3379637510737, 'scari side effect'), (-34.856845714148875, 'bowel syndrom constip'), (-35.14531033420699, 'not birth'), (-37.96051846131872, 'harsh side effect'), (-41.2499697944318, 'strang side effect'), (-41.76529159559362, 'swing headach'), (-44.42670296403282, 'immedi side effect'), (-58.770040215236804, 'daili panic')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=45000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 45000)\n",
      "(10694, 45000)\n",
      "(203167, 45938)\n",
      "(10694, 45938)\n",
      "(203167, 45939)\n",
      "(10694, 45939)\n",
      "TRAIN: MSE: 2.706838, RMSE: 1.135818, R^2: 0.747569\n",
      "TEST: MSE: 4.621547, RMSE: 1.295622, R^2: 0.575202\n",
      "[(25.81848152008107, 'marrow'), (19.907948689457918, 'magnesia'), (19.593425840003178, 'folic'), (19.579472549928408, 'fallopian tube'), (19.416318002511346, 'lo ovral'), (18.59449838692425, 'esteem'), (17.485379055709817, 'ice cube'), (16.280917113404804, 'natur throid'), (16.2077796825812, 'bleed complet'), (15.829852546136626, 'actin')]\n",
      "[(-17.42526739753384, 'actin keratosi'), (-18.57265174098299, 'connect dot'), (-18.60748359417772, 'benign prostat'), (-19.359838860928527, 'fallopian'), (-19.391132330260998, 'self esteem'), (-19.571032242384707, 'proton pump'), (-19.787575005838445, 'cube'), (-19.892182337101687, 'milk magnesia'), (-24.66731329909915, 'bone marrow'), (-29.909414291535878, 'blue shield')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=45000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 45000)\n",
      "(10694, 45000)\n",
      "(203167, 45938)\n",
      "(10694, 45938)\n",
      "(203167, 45939)\n",
      "(10694, 45939)\n",
      "TRAIN: MSE: 2.699313, RMSE: 1.133790, R^2: 0.748271\n",
      "TEST: MSE: 4.681281, RMSE: 1.300202, R^2: 0.569712\n",
      "[(55.08030068368711, 'daili panic attack'), (47.26804553146947, 'harsh side'), (42.40188650531638, 'mood swing headach'), (41.737149226323744, 'strang side'), (38.784978330655015, 'not birth control'), (37.867760199987316, 'pack per'), (37.309447405327255, 'immedi side'), (35.122479767103904, 'syndrom constip'), (34.38546773697537, 'pregnant birth control'), (34.23836680401752, 'viral load went')]\n",
      "[(-34.31496833300851, 'load went'), (-34.358181400027014, 'bowel syndrom constip'), (-35.21219831358773, 'scari side effect'), (-38.680315208794774, 'back birth control'), (-40.54029496186523, 'pack per day'), (-41.85816714631445, 'swing headach'), (-42.460096746757536, 'harsh side effect'), (-42.58732738570093, 'strang side effect'), (-43.99536755789249, 'immedi side effect'), (-57.04099314173162, 'daili panic')]\n",
      "\n",
      "Running ngram(1, 2)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=50000,\n",
      "                min_df=2, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 50000)\n",
      "(10694, 50000)\n",
      "(203167, 50938)\n",
      "(10694, 50938)\n",
      "(203167, 50939)\n",
      "(10694, 50939)\n",
      "TRAIN: MSE: 2.515387, RMSE: 1.114267, R^2: 0.765423\n",
      "TEST: MSE: 4.684631, RMSE: 1.295911, R^2: 0.569404\n",
      "[(52.377261472331, 'mgmt'), (39.01601386180521, 'supraventricular tachycardia'), (32.546887420416894, 'marrow'), (28.26772240211066, 'magnesia'), (22.236193498315036, 'esteem'), (21.741789311261076, 'steven'), (21.12708872699811, 'bismol'), (19.174328879270945, 'folic'), (19.085961557738052, 'lo ovral'), (19.077965022117645, 'ice cube')]\n",
      "[(-20.54294152105106, 'rite aid'), (-21.34893667083363, 'proton pump'), (-21.69152375433246, 'cube'), (-23.53866954179383, 'self esteem'), (-27.89525295351737, 'milk magnesia'), (-28.184401324779742, 'blue shield'), (-31.313785966535477, 'bone marrow'), (-32.10034724976425, 'supraventricular'), (-34.486020904482196, 'steven johnson'), (-55.947270721523964, 'pain mgmt')]\n",
      "\n",
      "Running ngram(1, 3)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=50000,\n",
      "                min_df=2, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(203167, 50000)\n",
      "(10694, 50000)\n",
      "(203167, 50938)\n",
      "(10694, 50938)\n",
      "(203167, 50939)\n",
      "(10694, 50939)\n",
      "TRAIN: MSE: 2.508557, RMSE: 1.112806, R^2: 0.766060\n",
      "TEST: MSE: 4.655780, RMSE: 1.297309, R^2: 0.572056\n",
      "[(60.78961953051713, 'harsh side'), (50.97862206579321, 'side effect gas'), (50.53247819458764, 'daili panic attack'), (50.223360125355875, 'fine ever sinc'), (49.01313001377598, 'strang side'), (44.823516938347396, 'mood swing headach'), (41.64196630259408, 'provera shot'), (41.35813909646559, 'not birth control'), (40.39236821961779, 'use pull method'), (38.70973339000698, 'pack per')]\n",
      "[(-37.87325292210376, 'depo provera shot'), (-38.27164928918026, 'find side effect'), (-40.21123794858385, 'pack per day'), (-43.690622357829575, 'immedi side effect'), (-44.16636645625409, 'swing headach'), (-45.00075613072519, 'fine ever'), (-47.23546706190037, 'effect gas'), (-49.76551936423472, 'strang side effect'), (-52.580568790543545, 'daili panic'), (-56.39953580791841, 'harsh side effect')]\n"
     ]
    }
   ],
   "source": [
    "# Features add condition & usefulCount\n",
    "# Test set 0.05\n",
    "for numFeatures in [20000, 25000, 30000, 35000, 40000, 45000, 50000]:\n",
    "    for max_ngram in [2, 3]: \n",
    "        min_ngram = 1\n",
    "\n",
    "        print(\"\\nRunning ngram(%d, %d)\" % (min_ngram, max_ngram))\n",
    "        train_data_features, test_data_features, vc = getTFIDFFeatures(min_ngram, max_ngram, df_train, df_test, numFeatures)\n",
    "        print(train_data_features.shape)\n",
    "        print(test_data_features.shape)\n",
    "\n",
    "        train_features = hstack((train_data_features,train_onehotlabels))\n",
    "        test_features = hstack((test_data_features,test_onehotlabels))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        # Useful Count\n",
    "        train_features = hstack((train_features, np.array([normUsefulCount_train]).T))\n",
    "        test_features = hstack((test_features, np.array([normUsefulCount_test]).T))\n",
    "        \n",
    "        print(train_features.shape)\n",
    "        print(test_features.shape)\n",
    "\n",
    "        model = getLinearRegressionResults(train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        #for c in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        #    getRidgeRegressionResults(c, train_features, df_train[\"rating\"], test_features, df_test[\"rating\"])\n",
    "\n",
    "        CoefNames = list(zip(model.coef_, vc.get_feature_names()))\n",
    "        CoefNames.sort(reverse=True)\n",
    "        print(CoefNames[:10])\n",
    "        print(CoefNames[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['vaderReviewScore'] = df2['cleanReview'].apply(lambda x: analyzer.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleanReview</th>\n",
       "      <th>vaderReviewScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>163740</td>\n",
       "      <td>\"I&amp;#039;ve tried a few antidepressants over th...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>\"I&amp;#039;ve tried antidepressants years (citalo...</td>\n",
       "      <td>0.7623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>206473</td>\n",
       "      <td>\"My son has Crohn&amp;#039;s disease and has done ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>\"My son Crohn&amp;#039;s disease done well Asacol....</td>\n",
       "      <td>0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>159672</td>\n",
       "      <td>\"Quick reduction of symptoms\"</td>\n",
       "      <td>9.0</td>\n",
       "      <td>\"Quick reduction symptoms\"</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>39293</td>\n",
       "      <td>\"Contrave combines drugs that were used for al...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>\"Contrave combines drugs used alcohol, smoking...</td>\n",
       "      <td>0.8115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>97768</td>\n",
       "      <td>\"I have been on this birth control for one cyc...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>\"I birth control one cycle. After reading revi...</td>\n",
       "      <td>0.9619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>208087</td>\n",
       "      <td>\"4 days in on first 2 weeks.  Using on arms an...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>\"4 days first 2 weeks. Using arms face. Put va...</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>215892</td>\n",
       "      <td>\"I&amp;#039;ve had the copper coil for about 3 mon...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>\"I&amp;#039;ve copper coil 3 months now. I really ...</td>\n",
       "      <td>-0.8319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>169852</td>\n",
       "      <td>\"This has been great for me. I&amp;#039;ve been on...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>\"This great me. I&amp;#039;ve 2 weeks last week I ...</td>\n",
       "      <td>0.7964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>23295</td>\n",
       "      <td>\"Ive been on Methadone for over ten years and ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>\"Ive Methadone ten years currently,I trying ge...</td>\n",
       "      <td>-0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>71428</td>\n",
       "      <td>\"I was on this pill for almost two years. It d...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"I pill almost two years. It work far getting ...</td>\n",
       "      <td>-0.8834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>196802</td>\n",
       "      <td>\"Holy Hell is exactly how I feel. I had been t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"Holy Hell exactly I feel. I taking Brisdelle ...</td>\n",
       "      <td>-0.6373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>31947</td>\n",
       "      <td>\"Honestly its day one on the 3 day treatment. ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>\"Honestly day one 3 day treatment. Yes burns b...</td>\n",
       "      <td>0.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4907</td>\n",
       "      <td>\"This is a waste of money.  Did not curb my ap...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\"This waste money. Did curb appetite make feel...</td>\n",
       "      <td>-0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>66736</td>\n",
       "      <td>\"No problems, watch what you eat.\"</td>\n",
       "      <td>10.0</td>\n",
       "      <td>\"No problems, watch eat.\"</td>\n",
       "      <td>-0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>97013</td>\n",
       "      <td>\"Ditto on rebound sleepless when discontinued....</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"Ditto rebound sleepless discontinued. I done ...</td>\n",
       "      <td>-0.5574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>213376</td>\n",
       "      <td>\"A doctor in the ER prescribed me 200 mg of Pr...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>\"A doctor ER prescribed 200 mg Provigil I firs...</td>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>151674</td>\n",
       "      <td>\"I smoked for 50+ years.  Took it for one week...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>\"I smoked 50+ years. Took one week it. I didn&amp;...</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>33173</td>\n",
       "      <td>\"So I was on Ginanvi for about 3 months before...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>\"So I Ginanvi 3 months I switched pill due hig...</td>\n",
       "      <td>-0.9531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>30401</td>\n",
       "      <td>\"This medication helped me  sleep, but eventua...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>\"This medication helped sleep, eventually beca...</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>152490</td>\n",
       "      <td>\"After just 1 dose of this ciprofloxacn, I fel...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>\"After 1 dose ciprofloxacn, I felt 99% better.\"</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                             review  rating  \\\n",
       "0   163740  \"I&#039;ve tried a few antidepressants over th...    10.0   \n",
       "1   206473  \"My son has Crohn&#039;s disease and has done ...     8.0   \n",
       "2   159672                      \"Quick reduction of symptoms\"     9.0   \n",
       "3    39293  \"Contrave combines drugs that were used for al...     9.0   \n",
       "4    97768  \"I have been on this birth control for one cyc...     9.0   \n",
       "5   208087  \"4 days in on first 2 weeks.  Using on arms an...     4.0   \n",
       "6   215892  \"I&#039;ve had the copper coil for about 3 mon...     6.0   \n",
       "7   169852  \"This has been great for me. I&#039;ve been on...     9.0   \n",
       "8    23295  \"Ive been on Methadone for over ten years and ...     7.0   \n",
       "9    71428  \"I was on this pill for almost two years. It d...     2.0   \n",
       "10  196802  \"Holy Hell is exactly how I feel. I had been t...     1.0   \n",
       "11   31947  \"Honestly its day one on the 3 day treatment. ...     6.0   \n",
       "12    4907  \"This is a waste of money.  Did not curb my ap...     1.0   \n",
       "13   66736                 \"No problems, watch what you eat.\"    10.0   \n",
       "14   97013  \"Ditto on rebound sleepless when discontinued....     2.0   \n",
       "15  213376  \"A doctor in the ER prescribed me 200 mg of Pr...     9.0   \n",
       "16  151674  \"I smoked for 50+ years.  Took it for one week...    10.0   \n",
       "17   33173  \"So I was on Ginanvi for about 3 months before...     3.0   \n",
       "18   30401  \"This medication helped me  sleep, but eventua...     6.0   \n",
       "19  152490  \"After just 1 dose of this ciprofloxacn, I fel...    10.0   \n",
       "\n",
       "                                          cleanReview  vaderReviewScore  \n",
       "0   \"I&#039;ve tried antidepressants years (citalo...            0.7623  \n",
       "1   \"My son Crohn&#039;s disease done well Asacol....            0.4767  \n",
       "2                          \"Quick reduction symptoms\"            0.0000  \n",
       "3   \"Contrave combines drugs used alcohol, smoking...            0.8115  \n",
       "4   \"I birth control one cycle. After reading revi...            0.9619  \n",
       "5   \"4 days first 2 weeks. Using arms face. Put va...            0.3818  \n",
       "6   \"I&#039;ve copper coil 3 months now. I really ...           -0.8319  \n",
       "7   \"This great me. I&#039;ve 2 weeks last week I ...            0.7964  \n",
       "8   \"Ive Methadone ten years currently,I trying ge...           -0.2500  \n",
       "9   \"I pill almost two years. It work far getting ...           -0.8834  \n",
       "10  \"Holy Hell exactly I feel. I taking Brisdelle ...           -0.6373  \n",
       "11  \"Honestly day one 3 day treatment. Yes burns b...            0.7184  \n",
       "12  \"This waste money. Did curb appetite make feel...           -0.4215  \n",
       "13                          \"No problems, watch eat.\"           -0.5994  \n",
       "14  \"Ditto rebound sleepless discontinued. I done ...           -0.5574  \n",
       "15  \"A doctor ER prescribed 200 mg Provigil I firs...            0.6903  \n",
       "16  \"I smoked 50+ years. Took one week it. I didn&...            0.6249  \n",
       "17  \"So I Ginanvi 3 months I switched pill due hig...           -0.9531  \n",
       "18  \"This medication helped sleep, eventually beca...           -0.4019  \n",
       "19    \"After 1 dose ciprofloxacn, I felt 99% better.\"            0.0000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
